{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ltcsRQJ7o31N"
   },
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import os\n",
    "import os.path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import sqrt\n",
    "from heapq import nlargest\n",
    "from tqdm import trange\n",
    "from tqdm import tqdm\n",
    "from scipy import stats\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "path = 'ml-100k'\n",
    "def getData(folder_path, file_name):\n",
    "    fields = ['userID', 'itemID', 'rating', 'timestamp']\n",
    "    data = pd.read_csv(os.path.join(folder_path, file_name), sep='\\t', names=fields)\n",
    "    return data \n",
    "\n",
    "rating_df = getData(path, 'u.data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  itemID  rating  timestamp\n",
       "0     196     242       3  881250949\n",
       "1     186     302       3  891717742\n",
       "2      22     377       1  878887116\n",
       "3     244      51       2  880606923\n",
       "4     166     346       1  886397596"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "5o4j_38xoqQF",
    "outputId": "5ca945c5-e451-4a0f-a6de-e3255b082542"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 943\n",
      "Number of items: 1682\n"
     ]
    }
   ],
   "source": [
    "num_users = len(rating_df.userID.unique())\n",
    "num_items = len(rating_df.itemID.unique())\n",
    "print(\"Number of users:\", num_users)\n",
    "print(\"Number of items:\", num_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eB3BnXJaoqSZ"
   },
   "outputs": [],
   "source": [
    "def dataPreprocessor(rating_df, num_users, num_items):\n",
    "    \"\"\"\n",
    "        INPUT: \n",
    "            data: pandas DataFrame. columns=['userID', 'itemID', 'rating' ...]\n",
    "            num_row: int. number of users\n",
    "            num_col: int. number of items\n",
    "            \n",
    "        OUTPUT:\n",
    "            matrix: 2D numpy array. \n",
    "            \n",
    "        NOTE 1: see where something very similar is done in the lab in function 'buildUserItemMatrix'    \n",
    "            \n",
    "        NOTE 2: data can have more columns, but your function should ignore \n",
    "              additional columns.\n",
    "    \"\"\"\n",
    "    ########### your code goes here ###########\n",
    "\n",
    "    # Initialize a of size (numUsers, numItems) to zeros\n",
    "    matrix = np.zeros((num_users, num_items), dtype=np.int8)\n",
    "    \n",
    "    # Populate the matrix based on the dataset\n",
    "    for (index, userID, itemID, rating, timestamp) in rating_df.itertuples():\n",
    "        matrix[userID-1, itemID-1] = rating\n",
    "    \n",
    "    \n",
    "    ###########         end         ###########\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 140
    },
    "colab_type": "code",
    "id": "z8h69CaroqVx",
    "outputId": "2cabef0f-b5f3-4946-8f96-7cfbacbc4e52"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 3, 4, ..., 0, 0, 0],\n",
       "       [4, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [5, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 5, 0, ..., 0, 0, 0]], dtype=int8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataPreprocessor(rating_df, num_users, num_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WK9unZg5rs66"
   },
   "outputs": [],
   "source": [
    "class BaseLineRecSys(object):\n",
    "    def __init__(self, method, processor=dataPreprocessor):\n",
    "        \"\"\"\n",
    "            method: string. From ['popularity','useraverage']\n",
    "            processor: function name. dataPreprocessor by default\n",
    "        \"\"\"\n",
    "        self.method_name = method\n",
    "        self.method = self._getMethod(self.method_name)\n",
    "        self.processor = processor\n",
    "        self.pred_column_name = self.method_name\n",
    "        \n",
    "    def _getMethod(self, method_name):\n",
    "        \"\"\"\n",
    "            Don't change this\n",
    "        \"\"\"\n",
    "        switcher = {\n",
    "            'popularity': self.popularity,\n",
    "            'useraverage': self.useraverage,\n",
    "        }\n",
    "        \n",
    "        return switcher[method_name]\n",
    "    \n",
    "    @staticmethod\n",
    "    def useraverage(train_matrix, num_users, num_items):\n",
    "        \"\"\"\n",
    "            INPUT:\n",
    "                train_matrix: 2D numpy array.\n",
    "                num_users: int. Number of Users.\n",
    "                num_items: int. Number of Items.\n",
    "            OUTPUT:\n",
    "                predictionMatrix: 2D numpy array.\n",
    "                \n",
    "            NOTE: see where something very similar is done in the lab in function 'predictByUserAverage'    \n",
    "        \"\"\"       \n",
    "        predictionMatrix = np.zeros((num_users, num_items))\n",
    "        ########### your code goes here ###########\n",
    "        # Initialize the predicted rating matrix with zeros\n",
    "            # Initialize the predicted rating matrix with zeros\n",
    "\n",
    "        for (user,item), rating in np.ndenumerate(train_matrix):\n",
    "            # Predict rating for every item that wasn't ranked by the user (rating == 0)\n",
    "            #if rating == 0:\n",
    "                # Extract the items the user already rated\n",
    "            userVector = train_matrix[user, :]\n",
    "            ratedItems = userVector[userVector.nonzero()]\n",
    "\n",
    "            # If not empty, calculate average and set as rating for the current item\n",
    "            if ratedItems.size == 0:\n",
    "                itemAvg = 0\n",
    "            else:\n",
    "                itemAvg = ratedItems.mean()\n",
    "            predictionMatrix[user, item] = itemAvg\n",
    "\n",
    "            # report progress every 100 users\n",
    "            if (user % 100 == 0 and item == 1):\n",
    "                print (\"calculated %d users\" % (user,))\n",
    "\n",
    "        ###########         end         ###########\n",
    "        return predictionMatrix\n",
    "    \n",
    "    @staticmethod\n",
    "    def popularity(train_matrix, num_users, num_items):\n",
    "        \"\"\"\n",
    "            INPUT:\n",
    "                train_matrix: 2D numpy array.\n",
    "                num_users: int. Number of Users.\n",
    "                num_items: int. Number of Items.\n",
    "            OUTPUT:\n",
    "                predictionMatrix: 2D numpy array.\n",
    "                \n",
    "            NOTE: see where something very similar is done in the lab in function 'predictByPopularity'    \n",
    "        \"\"\"\n",
    "   \n",
    "        # Initialize the predicted rating matrix with zeros\n",
    "        predictionMatrix = np.zeros((num_users, num_items))\n",
    "\n",
    "        # Define function for converting 1-5 rating to 0/1 (like / don't like)\n",
    "        vf = np.vectorize(lambda x: 1 if x >= 4 else 0)\n",
    "\n",
    "        # For every item calculate the number of people liked (4-5) divided by the number of people that rated\n",
    "        itemPopularity = np.zeros((num_items))\n",
    "        for item in range(num_items):\n",
    "            numOfUsersRated = len(train_matrix[:, item].nonzero()[0])\n",
    "            numOfUsersLiked = len(vf(train_matrix[:, item]).nonzero()[0])\n",
    "            if numOfUsersRated == 0:\n",
    "                itemPopularity[item] = 0\n",
    "            else:\n",
    "                itemPopularity[item] = numOfUsersLiked/numOfUsersRated\n",
    "\n",
    "        for (user,item), rating in np.ndenumerate(train_matrix):\n",
    "            # Predict rating for every item that wasn't ranked by the user (rating == 0)\n",
    "            #if rating == 0:\n",
    "            predictionMatrix[user, item] = itemPopularity[item]\n",
    "\n",
    "            # report progress every 100 users\n",
    "            if (user % 100 == 0 and item == 1):\n",
    "                print (\"calculated %d users\" % (user,))\n",
    "\n",
    "                  \n",
    "        ###########         end         ###########\n",
    "        return predictionMatrix    \n",
    "    \n",
    "    def predict_all(self, train_df, num_users, num_items):\n",
    "        \n",
    "        train_matrix = self.processor(train_df, num_users, num_items)\n",
    "        self.__model = self.method(train_matrix, num_users, num_items)\n",
    "        \n",
    "    def evaluate_test(self, test_df, copy=False):\n",
    "        \n",
    "        if copy:\n",
    "            prediction = test_df.copy()\n",
    "        else:\n",
    "            prediction = test_df\n",
    "            \n",
    "        prediction[self.pred_column_name] = np.nan\n",
    "        \n",
    "        for (index, \n",
    "             userID, \n",
    "             itemID) in tqdm(prediction[['userID','itemID']].itertuples()):\n",
    "            prediction.loc[index, self.pred_column_name] = self.__model[userID-1, itemID-1]\n",
    "\n",
    "        return prediction\n",
    "        \n",
    "    def getModel(self):\n",
    "        \"\"\"\n",
    "            return predicted user-item matrix\n",
    "        \"\"\"\n",
    "        return self.__model\n",
    "    \n",
    "    def getPredColName(self):\n",
    "        \"\"\"\n",
    "            return prediction column name\n",
    "        \"\"\"\n",
    "        return self.pred_column_name\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "            reuse the instance of the class by removing model\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.model = None\n",
    "        except:\n",
    "            print(\"You don not have model..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JnkG4TL8r9lz"
   },
   "outputs": [],
   "source": [
    "popularity_recsys = BaseLineRecSys('popularity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "colab_type": "code",
    "id": "ev0FU8HNr-Vr",
    "outputId": "6ff6b362-570f-4b2f-a03d-3bc66a51244e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    }
   ],
   "source": [
    "popularity_recsys.predict_all(rating_df, num_users, num_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SVqYNSscsDHO"
   },
   "outputs": [],
   "source": [
    "x = popularity_recsys.getModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "63QlJaq1sDJ0",
    "outputId": "d6631b42-a0b3-442a-8783-9ba3f5d5e50d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(x<=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 213
    },
    "colab_type": "code",
    "id": "ZvTkeF9KsDMF",
    "outputId": "3954e28f-4d5a-4418-f8df-caacf5985389"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100000it [00:58, 1715.90it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>popularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "      <td>0.760684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "      <td>0.804714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "      <td>0.076923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "      <td>0.611111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  itemID  rating  timestamp  popularity\n",
       "0     196     242       3  881250949    0.760684\n",
       "1     186     302       3  891717742    0.804714\n",
       "2      22     377       1  878887116    0.076923\n",
       "3     244      51       2  880606923    0.555556\n",
       "4     166     346       1  886397596    0.611111"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "popularity_recsys.evaluate_test(rating_df,copy=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tb8Hc-TTsjOE"
   },
   "outputs": [],
   "source": [
    "average_user_rating_recsys = BaseLineRecSys('useraverage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "colab_type": "code",
    "id": "bchRfpvcsjKz",
    "outputId": "e4c4e00f-ff45-47ee-dac8-3f52d40f2e60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    }
   ],
   "source": [
    "average_user_rating_recsys.predict_all(rating_df, num_users, num_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 246
    },
    "colab_type": "code",
    "id": "yiN0YJOTsjI2",
    "outputId": "b672af18-c486-4c07-e701-5aace7bf30e7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.61029412, 3.61029412, 3.61029412, ..., 3.61029412, 3.61029412,\n",
       "        3.61029412],\n",
       "       [3.70967742, 3.70967742, 3.70967742, ..., 3.70967742, 3.70967742,\n",
       "        3.70967742],\n",
       "       [2.7962963 , 2.7962963 , 2.7962963 , ..., 2.7962963 , 2.7962963 ,\n",
       "        2.7962963 ],\n",
       "       ...,\n",
       "       [4.04545455, 4.04545455, 4.04545455, ..., 4.04545455, 4.04545455,\n",
       "        4.04545455],\n",
       "       [4.26582278, 4.26582278, 4.26582278, ..., 4.26582278, 4.26582278,\n",
       "        4.26582278],\n",
       "       [3.41071429, 3.41071429, 3.41071429, ..., 3.41071429, 3.41071429,\n",
       "        3.41071429]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_user_rating_recsys.getModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 213
    },
    "colab_type": "code",
    "id": "PbBpl-ZPsjGV",
    "outputId": "32af19ba-e2d6-4dd8-f086-20320cde54e0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100000it [00:49, 2015.05it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>useraverage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "      <td>3.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "      <td>3.413043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "      <td>3.351562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "      <td>3.651261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "      <td>3.550000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  itemID  rating  timestamp  useraverage\n",
       "0     196     242       3  881250949     3.615385\n",
       "1     186     302       3  891717742     3.413043\n",
       "2      22     377       1  878887116     3.351562\n",
       "3     244      51       2  880606923     3.651261\n",
       "4     166     346       1  886397596     3.550000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_user_rating_recsys.evaluate_test(rating_df,copy=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A0csD4wMsjDs"
   },
   "outputs": [],
   "source": [
    "class SimBasedRecSys(object):\n",
    "\n",
    "    def __init__(self, base, method, processor=dataPreprocessor):\n",
    "        \"\"\"\n",
    "            base: string. From ['user', 'item']. User-based Similarity or Item-based\n",
    "            method: string. From ['cosine', 'euclidean', 'somethingelse']\n",
    "            processor: function name. dataPreprocessor by default\n",
    "        \"\"\"\n",
    "        self.base = base\n",
    "        self.method_name = method\n",
    "        self.method = self._getMethod(self.method_name)\n",
    "        self.processor = processor\n",
    "        self.pred_column_name = self.base+'-'+self.method_name\n",
    "    \n",
    "    def _getMethod(self, method_name):\n",
    "        \"\"\"\n",
    "            Don't change this\n",
    "        \"\"\"\n",
    "        switcher = {\n",
    "            'cosine': self.cosine,\n",
    "            'euclidean': self.euclidean,\n",
    "            'somethingelse': self.somethingelse,\n",
    "        }\n",
    "        \n",
    "        return switcher[method_name]\n",
    "    \n",
    "    @staticmethod\n",
    "    def cosine(matrix):\n",
    "        \"\"\"\n",
    "            cosine similarity\n",
    "        \"\"\"\n",
    "        similarity_matrix = 1 - pairwise_distances(matrix, metric='cosine')\n",
    "        return similarity_matrix\n",
    "    \n",
    "    @staticmethod\n",
    "    def euclidean(matrix):\n",
    "        \"\"\"\n",
    "            euclidean similarity\n",
    "        \"\"\"\n",
    "        ########### your code goes here ###########\n",
    "\n",
    "        similarity_matrix = 1 /(1 + pairwise_distances(matrix, metric='euclidean'))\n",
    "    \n",
    "        ###########         end         ###########    \n",
    "        \n",
    "        return similarity_matrix\n",
    "    \n",
    "    @staticmethod\n",
    "    def somethingelse(matrix):\n",
    "        \"\"\"\n",
    "            manhattan? or super-natural intuition similarity\n",
    "        \"\"\"\n",
    "        ########### your code goes here ###########\n",
    "    \n",
    "        similarity_matrix = 1 /(1 + pairwise_distances(matrix, metric='manhattan'))\n",
    "    \n",
    "    \n",
    "        ###########         end         ###########        \n",
    "        return similarity_matrix\n",
    "        \n",
    "    def predict_all(self, train_df, num_users, num_items):\n",
    "        \"\"\"\n",
    "            INPUT: \n",
    "                data: pandas DataFrame. columns=['userID', 'itemID', 'rating'...]\n",
    "                num_row: scalar. number of users\n",
    "                num_col: scalar. number of items\n",
    "            OUTPUT:\n",
    "                no return... this method assigns the result to self.model\n",
    "            \n",
    "            NOTES:\n",
    "                self.__model should contain predictions for *all* user and items\n",
    "                (don't worry about predicting for observed (user,item) pairs,\n",
    "                 since we won't be using these predictions in the evaluation)\n",
    "                (see code in for an efficient vectorized example)\n",
    "        \"\"\"\n",
    "        train_matrix = self.processor(train_df, num_users, num_items)\n",
    "        \n",
    "        if self.base == 'user':\n",
    "            ########### your code goes here ###########\n",
    "\n",
    "            # Initialize the predicted rating matrix with zeros\n",
    "            temp_matrix = np.zeros(train_matrix.shape)\n",
    "            temp_matrix[train_matrix.nonzero()] = 1\n",
    "            uu_similarity = self.method(train_matrix)\n",
    "    #         if k is not None:\n",
    "    #             uu_similarity = kNearestNeighbor(uu_similarity, k)\n",
    "            normalizer = np.matmul(uu_similarity, temp_matrix)\n",
    "            normalizer[normalizer == 0] = 1e-5\n",
    "            predictionMatrix = np.matmul(uu_similarity, train_matrix)/normalizer\n",
    "            #predictionMatrix[temp_matrix.nonzero()] = 0\n",
    "            #Cold start\n",
    "            \n",
    "            \n",
    "            normatempsum = np.sum(temp_matrix, axis=1)\n",
    "            normatempsum[normatempsum == 0] = 1e-5\n",
    "            useraverage = np.sum(train_matrix, axis=1)/normatempsum\n",
    "            columns = np.sum(predictionMatrix, axis=0)\n",
    "            predictionMatrix[:, columns==0] = predictionMatrix[:, columns==0] + np.expand_dims(useraverage, axis=1)\n",
    "\n",
    "            self.__model = predictionMatrix  \n",
    "                      \n",
    "            ###########         end         ###########\n",
    "            \n",
    "        elif self.base == 'item':\n",
    "            ########### your code goes here ###########\n",
    "            \n",
    "            train_matrix = train_matrix.transpose()    \n",
    "\n",
    "            # Initialize the predicted rating matrix with zeros\n",
    "            temp_matrix = np.zeros(train_matrix.shape)\n",
    "            temp_matrix[train_matrix.nonzero()] = 1\n",
    "            uu_similarity = self.method(train_matrix)\n",
    "    #         if k is not None:\n",
    "    #             uu_similarity = kNearestNeighbor(uu_similarity, k)\n",
    "            normalizer = np.matmul(uu_similarity, temp_matrix)\n",
    "            normalizer[normalizer == 0] = 1e-5\n",
    "            predictionMatrix = np.matmul(uu_similarity, train_matrix)/normalizer\n",
    "            #predictionMatrix[temp_matrix.nonzero()] = 0\n",
    "            #Cold start\n",
    "            \n",
    "            \n",
    "            normatempsum = np.sum(temp_matrix, axis=1)\n",
    "            normatempsum[normatempsum == 0] = 1e-5\n",
    "            useraverage = np.sum(train_matrix, axis=1)/normatempsum\n",
    "            columns = np.sum(predictionMatrix, axis=0)\n",
    "            predictionMatrix[:, columns==0] = predictionMatrix[:, columns==0] + np.expand_dims(useraverage, axis=1)\n",
    "\n",
    "            self.__model = predictionMatrix.transpose()\n",
    "            \n",
    "          \n",
    "            ###########         end         ###########\n",
    "        else:\n",
    "            print('No other option available')\n",
    "        \n",
    "    def evaluate_test(self, test_df, copy=False):\n",
    "        \"\"\"\n",
    "            INPUT:\n",
    "                data: pandas DataFrame. columns=['userID', 'itemID', 'rating'...]\n",
    "            OUTPUT:\n",
    "                predictions:  pandas DataFrame. \n",
    "                              columns=['userID', 'itemID', 'rating', 'base-method'...]\n",
    "                              \n",
    "            NOTE: 1. data can have more columns, but your function should ignore \n",
    "                  additional columns.\n",
    "                  2. 'base-method' depends on your 'base' and 'method'. For example,\n",
    "                  if base == 'user' and method == 'cosine', \n",
    "                  then base-method == 'user-cosine'\n",
    "                  3. your predictions go to 'base-method' column\n",
    "        \"\"\"\n",
    "        if copy:\n",
    "            prediction = test_df.copy()\n",
    "        else:\n",
    "            prediction = test_df\n",
    "        prediction[self.pred_column_name] = np.nan\n",
    "        \n",
    "        for (index, \n",
    "             userID, \n",
    "             itemID) in tqdm(prediction[['userID','itemID']].itertuples()):\n",
    "            prediction.loc[index, self.pred_column_name] = self.__model[userID-1, itemID-1]\n",
    "    \n",
    "        return prediction\n",
    "    \n",
    "    def getModel(self):\n",
    "        \"\"\"\n",
    "            return predicted user-item matrix\n",
    "        \"\"\"\n",
    "        return self.__model\n",
    "    \n",
    "    def getPredColName(self):\n",
    "        \"\"\"\n",
    "            return prediction column name\n",
    "        \"\"\"\n",
    "        return self.pred_column_name\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "            reuse the instance of the class by removing model\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.model = None\n",
    "        except:\n",
    "            print(\"You do not have model..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1.],\n",
       "       [1., 1.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I = [[1,1],[5,5]]\n",
    "SimBasedRecSys.cosine(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I = np.eye(3)\n",
    "SimBasedRecSys.cosine(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.41421356, 0.41421356],\n",
       "       [0.41421356, 1.        , 0.41421356],\n",
       "       [0.41421356, 0.41421356, 1.        ]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SimBasedRecSys.euclidean(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.33333333, 0.33333333],\n",
       "       [0.33333333, 1.        , 0.33333333],\n",
       "       [0.33333333, 0.33333333, 1.        ]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SimBasedRecSys.somethingelse(I)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis: \n",
    "* Cosine works better than Euclidean mainly due to length normalization.\n",
    "* But in our case we also normalized values of Euclidean so both are having overlap in confidence intervals for RMSE.\n",
    "* For example If I have two users who rated (4,4) and (5,5) two movies they can still be similar because each user has different relative perspectives both of them didnt hate the movie. So in this case cosine works better than Euclidean.\n",
    "* For example If I have two user who rated (1,1) and (5,5) two movies. Cosine says they are similar but clearly they are not.\n",
    "* From our results in Q4\n",
    "'user-euclidean': [[1.0319953645887305, 1.013706565892023, 1.031268958300787], 'item-euclidean': [[1.0452460304884215, 1.0157114777932958, 1.0413212192481176]}\n",
    "'user-cosine': [[1.026449013124381, 1.009013080226148, 1.0256951630950135], 'item-cosine': [[1.0377631264364244, 1.0068242686250732, 1.0333415315874226]}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manhattan is choosen because it calculates the distance of two vectors by absolute differences. It is similar to Euclidean because we are normalizing both of them (similar results checked in bottom). In case of manhattan it is more robust and it requires less calculations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MnKe5CDfsjBH"
   },
   "outputs": [],
   "source": [
    "user_cosine_recsys = SimBasedRecSys('user','cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1fbfyE3FtXZK"
   },
   "outputs": [],
   "source": [
    "item_cosine_recsys = SimBasedRecSys('item','cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TeIqY0J4tXbZ"
   },
   "outputs": [],
   "source": [
    "user_cosine_recsys.predict_all(rating_df, num_users, num_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 246
    },
    "colab_type": "code",
    "id": "y5mdbxj-tXd7",
    "outputId": "4d85bcc8-d1e6-4251-b30f-90edbbe157e1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.89911175, 3.19022667, 3.0261129 , ..., 2.        , 3.        ,\n",
       "        3.        ],\n",
       "       [3.84034456, 3.17139889, 2.92626717, ..., 2.        , 3.        ,\n",
       "        3.        ],\n",
       "       [3.87104065, 3.12823798, 3.03250708, ..., 2.        , 3.        ,\n",
       "        3.        ],\n",
       "       ...,\n",
       "       [3.90754645, 3.20227238, 3.05776201, ..., 2.        , 3.        ,\n",
       "        3.        ],\n",
       "       [3.91100649, 3.21591021, 2.98854017, ..., 2.        , 3.        ,\n",
       "        3.        ],\n",
       "       [3.91593122, 3.24268207, 3.08255897, ..., 0.        , 3.        ,\n",
       "        3.        ]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_cosine_recsys.getModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 213
    },
    "colab_type": "code",
    "id": "ftlgeqEHtXhL",
    "outputId": "10ea49e7-a13f-46d7-f47a-edbbe8e41ce3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100000it [01:52, 884.99it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user-cosine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "      <td>4.025213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "      <td>4.142828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "      <td>1.922080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "      <td>3.431884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "      <td>3.424963</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  itemID  rating  timestamp  user-cosine\n",
       "0     196     242       3  881250949     4.025213\n",
       "1     186     302       3  891717742     4.142828\n",
       "2      22     377       1  878887116     1.922080\n",
       "3     244      51       2  880606923     3.431884\n",
       "4     166     346       1  886397596     3.424963"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_cosine_recsys.evaluate_test(rating_df,copy=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 361
    },
    "colab_type": "code",
    "id": "_xKrNxAKt50L",
    "outputId": "46dd996b-7b04-4989-e237-da127789c32f"
   },
   "outputs": [],
   "source": [
    "class CrossValidation(object):\n",
    "    def __init__(self, metric, data_path=path):\n",
    "        \"\"\"\n",
    "            INPUT:\n",
    "                metric: string. from['RMSE','P@K','R@K']\n",
    "        \"\"\"\n",
    "        self.folds = self._getData(path)\n",
    "        self.metric_name = metric\n",
    "        self.metric = self._getMetric(self.metric_name)\n",
    "        \n",
    "    def _getMetric(self, metric_name):\n",
    "        \"\"\"\n",
    "            Don't change this\n",
    "        \"\"\"\n",
    "        switcher = {\n",
    "            'RMSE': self.rmse,\n",
    "            'P@K': self.patk,\n",
    "            'R@K': self.ratk,\n",
    "        }\n",
    "        \n",
    "        return switcher[metric_name]\n",
    "    \n",
    "    @staticmethod\n",
    "    def rmse(data, k, num_users, num_items, pred, true='rating'):\n",
    "        \"\"\"\n",
    "            data: pandas DataFrame. \n",
    "            pred: string. Column name that corresponding to the prediction\n",
    "            true: string. Column name that corresponding to the true rating\n",
    "        \"\"\"\n",
    "        return sqrt(mean_squared_error(data[pred], data[true]))\n",
    "    \n",
    "    # Precision at k\n",
    "    def patk(self, data, k, num_users, num_items, pred, true='rating'):\n",
    "        \"\"\"\n",
    "            data: pandas DataFrame. \n",
    "            k: top-k items retrived\n",
    "            pred: string. Column name that corresponding to the prediction\n",
    "            true: string. Column name that corresponding to the true rating\n",
    "        \"\"\"\n",
    "        prediction = self.getMatrix(data, num_users, num_items, pred)\n",
    "        testSet =  self.getMatrix(data, num_users, num_items, true)\n",
    "    \n",
    "        # Initialize sum and count vars for average calculation\n",
    "        sumPrecisions = 0\n",
    "        countPrecisions = 0\n",
    "\n",
    "        # Define function for converting 1-5 rating to 0/1 (like / don't like)\n",
    "        vf = np.vectorize(lambda x: 1 if x >= 4 else 0)\n",
    "\n",
    "        for userID in range(num_users):\n",
    "            # Pick top K based on predicted rating\n",
    "            userVector = prediction[userID,:]\n",
    "            topK = nlargest(k, range(len(userVector)), userVector.take)\n",
    "\n",
    "            # Convert test set ratings to like / don't like\n",
    "            userTestVector = vf(testSet[userID,:]).nonzero()[0]\n",
    "\n",
    "            # Calculate precision\n",
    "            precision = float(len([item for item in topK if item in userTestVector]))/len(topK)\n",
    "\n",
    "            # Update sum and count\n",
    "            sumPrecisions += precision\n",
    "            countPrecisions += 1\n",
    "\n",
    "        # Return average P@k\n",
    "        return float(sumPrecisions)/countPrecisions\n",
    "    \n",
    "    # Recall at k\n",
    "    def ratk(self, data, k, num_users, num_items, pred, true='rating'):\n",
    "        \"\"\"\n",
    "            data: pandas DataFrame. \n",
    "            k: top-k items relevant\n",
    "            pred: string. Column name that corresponding to the prediction\n",
    "            true: string. Column name that corresponding to the true rating\n",
    "        \"\"\"\n",
    "        prediction = self.getMatrix(data, num_users, num_items, pred)\n",
    "        testSet =  self.getMatrix(data, num_users, num_items, true)\n",
    "        # Initialize sum and count vars for average calculation\n",
    "        sumRecalls = 0\n",
    "        countRecalls = 0\n",
    "\n",
    "        # Define function for converting 1-5 rating to 0/1 (like / don't like)\n",
    "        vf = np.vectorize(lambda x: 1 if x >= 4 else 0)\n",
    "\n",
    "        for userID in range(num_users):\n",
    "            # Pick top K based on predicted rating\n",
    "            userVector = prediction[userID,:]\n",
    "            topK = nlargest(k, range(len(userVector)), userVector.take)\n",
    "\n",
    "            # Convert test set ratings to like / don't like\n",
    "            userTestVector = vf(testSet[userID,:]).nonzero()[0]\n",
    "\n",
    "            # Ignore user if has no ratings in the test set\n",
    "            if (len(userTestVector) == 0):\n",
    "                continue\n",
    "\n",
    "            # Calculate recall\n",
    "            recall = float(len([item for item in topK if item in userTestVector]))/len(userTestVector)\n",
    "\n",
    "            # Update sum and count\n",
    "            sumRecalls += recall\n",
    "            countRecalls += 1\n",
    "\n",
    "        # Return average R@k\n",
    "        return float(sumRecalls)/countRecalls\n",
    "    \n",
    "    @staticmethod\n",
    "    def getMatrix(rating_df, num_users, num_items, column_name):\n",
    "        matrix = np.zeros((num_users, num_items))\n",
    "    \n",
    "        for (index, userID, itemID, value) in rating_df[['userID','itemID', column_name]].itertuples():\n",
    "            matrix[userID-1, itemID-1] = value\n",
    "            \n",
    "        return matrix\n",
    "    \n",
    "    @staticmethod\n",
    "    def _getData(data_path):\n",
    "        \"\"\"\n",
    "            Don't change this function\n",
    "        \"\"\"\n",
    "        folds = []\n",
    "        data_types = ['u{0}.base','u{0}.test']\n",
    "        for i in range(1,6):\n",
    "            train_set = getData(data_path, data_types[0].format(i))\n",
    "            test_set = getData(data_path, data_types[1].format(i))\n",
    "            folds.append([train_set, test_set])\n",
    "        return folds\n",
    "    \n",
    "    def run(self, algorithms, num_users, num_items, k=1):\n",
    "        \"\"\"\n",
    "            5-fold cross-validation\n",
    "            algorithms: list. a list of algorithms. \n",
    "                        eg: [user_cosine_recsys, item_euclidean_recsys]\n",
    "        \"\"\"\n",
    "        \n",
    "        scores = {}\n",
    "        for algorithm in algorithms:\n",
    "            print('Processing algorithm {0}'.format(algorithm.getPredColName()))\n",
    "            fold_scores = []\n",
    "            for fold in self.folds:\n",
    "                algorithm.reset()\n",
    "                algorithm.predict_all(fold[0], num_users, num_items)\n",
    "                prediction = algorithm.evaluate_test(fold[1])\n",
    "                pred_col = algorithm.getPredColName()\n",
    "                fold_scores.append(self.metric(prediction, k, num_users, num_items, pred_col))\n",
    "                \n",
    "            mean = np.mean(fold_scores)\n",
    "            ci_low, ci_high = stats.t.interval(0.95, len(fold_scores)-1, loc=mean, scale=stats.sem(fold_scores))\n",
    "            scores[algorithm.getPredColName()] = [fold_scores, mean, ci_low, ci_high]\n",
    "            \n",
    "        results = scores    \n",
    "    \n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RbF_3ordt52k"
   },
   "outputs": [],
   "source": [
    "# How to use CrossValidation Class?\n",
    "# 1. gather your algorithms in previous steps.\n",
    "algorithm_instances = [popularity_recsys, \n",
    "                       average_user_rating_recsys, \n",
    "                       user_cosine_recsys,\n",
    "                       item_cosine_recsys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gm2eTHQjt552"
   },
   "outputs": [],
   "source": [
    "# 2. Instantiate a CrossValidation instance and assign the measurement that you want to use\n",
    "# RMSE, P@K, R@K\n",
    "# Precision at K in this example\n",
    "cv_patk = CrossValidation('RMSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Raif1wUfuNRP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing algorithm popularity\n",
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:06, 3329.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:05, 3413.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:06, 3306.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:05, 3430.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:05, 3421.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing algorithm useraverage\n",
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:05, 3421.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:06, 3024.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:05, 3385.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:05, 3422.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:05, 3365.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing algorithm user-cosine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:05, 3348.95it/s]\n",
      "20000it [00:05, 3434.38it/s]\n",
      "20000it [00:05, 3410.78it/s]\n",
      "20000it [00:05, 3349.49it/s]\n",
      "20000it [00:05, 3451.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing algorithm item-cosine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:05, 3354.53it/s]\n",
      "20000it [00:05, 3436.43it/s]\n",
      "20000it [00:05, 3438.37it/s]\n",
      "20000it [00:06, 3332.37it/s]\n",
      "20000it [00:05, 3422.64it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'popularity': [[3.177941281084362,\n",
       "   3.1750480150769977,\n",
       "   3.147474655005899,\n",
       "   3.146164503024159,\n",
       "   3.1488360007536382],\n",
       "  3.1590928909890112,\n",
       "  3.139292746995387,\n",
       "  3.1788930349826354],\n",
       " 'useraverage': [[1.0629951276561334,\n",
       "   1.0467467492319966,\n",
       "   1.0328964562995389,\n",
       "   1.0366575971298078,\n",
       "   1.0392923504800367],\n",
       "  1.0437176561595025,\n",
       "  1.0289303496379316,\n",
       "  1.0585049626810734],\n",
       " 'user-cosine': [[1.026449013124381,\n",
       "   1.0214387664779507,\n",
       "   1.0132940326457187,\n",
       "   1.0094003999022947,\n",
       "   1.0161883961525586],\n",
       "  1.0173541216605808,\n",
       "  1.009013080226148,\n",
       "  1.0256951630950135],\n",
       " 'item-cosine': [[1.0377631264364244,\n",
       "   1.0207280585350078,\n",
       "   1.0101820660011798,\n",
       "   1.0136832839209695,\n",
       "   1.0180579656376574],\n",
       "  1.020082900106248,\n",
       "  1.0068242686250732,\n",
       "  1.0333415315874226]}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Run CV by giving:\n",
    "#    1> algorithms just gathered\n",
    "#    2> number of users in the full dataset\n",
    "#    3> number of items in the full dataset\n",
    "#    4> precision or recall at K need a K value, so k=5 means precision at 5 in this example\n",
    "# Results include independent results from 5 folds, their mean, and confidence interval.\n",
    "cv_patk.run(algorithm_instances, num_users, num_items,k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QPddj53quNTb"
   },
   "outputs": [],
   "source": [
    "q3df = dataPreprocessor(rating_df, num_users, num_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PO_MyImkuNVg"
   },
   "outputs": [],
   "source": [
    "temp_matrix = np.zeros(q3df.shape)\n",
    "temp_matrix[q3df.nonzero()] = 1 \n",
    "sumperrow = np.sum(temp_matrix, axis=1)\n",
    "averagenumberofratingsperuser = (sumperrow.sum())/943\n",
    "averagenumberofratingsperitem = (sumperrow.sum())/1682"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xQkUqCSguNYu"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59.45303210463734"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "averagenumberofratingsperitem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CE9M__GEuNbC"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106.04453870625663"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "averagenumberofratingsperuser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis: \n",
    "* The following values are RMSE average, low CI and high CI\n",
    "'item-cosine': [ 1.020, 1.006, 1.033,\n",
    "'user-cosine': [ 1.017, 1.009, 1.025,\n",
    "\n",
    "* If we see the RMSE results the user is performing slightly better because in our case the average number of ratings per user 106 is more than the average number of ratings per item 59. So while using similarity metrics in case of users we have more rich vectors to find out the similar ones. so better predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZoHvobpfuNdj"
   },
   "outputs": [],
   "source": [
    "item_cosine_recsys = SimBasedRecSys('item','cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5KTRXIdnuNil"
   },
   "outputs": [],
   "source": [
    "user_cosine_recsys = SimBasedRecSys('user','cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jx-mJY8suNlq"
   },
   "outputs": [],
   "source": [
    "# 1. gather your algorithms in previous steps.\n",
    "algorithm_instances = [popularity_recsys, \n",
    "                       average_user_rating_recsys, \n",
    "                       user_cosine_recsys,\n",
    "                       item_cosine_recsys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tY1unenXuNgi"
   },
   "outputs": [],
   "source": [
    "cv_patk = CrossValidation('RMSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7lEYFE1futTL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing algorithm popularity\n",
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:06, 3295.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:06, 3232.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:05, 3351.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:05, 3404.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:06, 3273.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing algorithm useraverage\n",
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:06, 3272.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:05, 3359.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:05, 3404.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:05, 3439.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:05, 3403.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing algorithm user-cosine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:06, 3316.56it/s]\n",
      "20000it [00:05, 3449.75it/s]\n",
      "20000it [00:05, 3441.06it/s]\n",
      "20000it [00:06, 3317.58it/s]\n",
      "20000it [00:05, 3449.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing algorithm item-cosine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:06, 3289.40it/s]\n",
      "20000it [00:05, 3430.21it/s]\n",
      "20000it [00:05, 3428.52it/s]\n",
      "20000it [00:06, 3272.64it/s]\n",
      "20000it [00:05, 3467.53it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'popularity': [[3.177941281084362,\n",
       "   3.1750480150769977,\n",
       "   3.147474655005899,\n",
       "   3.146164503024159,\n",
       "   3.1488360007536382],\n",
       "  3.1590928909890112,\n",
       "  3.139292746995387,\n",
       "  3.1788930349826354],\n",
       " 'useraverage': [[1.0629951276561334,\n",
       "   1.0467467492319966,\n",
       "   1.0328964562995389,\n",
       "   1.0366575971298078,\n",
       "   1.0392923504800367],\n",
       "  1.0437176561595025,\n",
       "  1.0289303496379316,\n",
       "  1.0585049626810734],\n",
       " 'user-cosine': [[1.026449013124381,\n",
       "   1.0214387664779507,\n",
       "   1.0132940326457187,\n",
       "   1.0094003999022947,\n",
       "   1.0161883961525586],\n",
       "  1.0173541216605808,\n",
       "  1.009013080226148,\n",
       "  1.0256951630950135],\n",
       " 'item-cosine': [[1.0377631264364244,\n",
       "   1.0207280585350078,\n",
       "   1.0101820660011798,\n",
       "   1.0136832839209695,\n",
       "   1.0180579656376574],\n",
       "  1.020082900106248,\n",
       "  1.0068242686250732,\n",
       "  1.0333415315874226]}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_patk.run(algorithm_instances, num_users, num_items,k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Omunlk1lutVj"
   },
   "outputs": [],
   "source": [
    "cv_patk = CrossValidation('P@K')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ihrzrK1KutX0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing algorithm popularity\n",
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:06, 3281.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:05, 3414.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:06, 3306.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:05, 3459.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:05, 3358.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing algorithm useraverage\n",
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:05, 3419.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:05, 3402.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:05, 3440.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:05, 3446.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:05, 3464.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing algorithm user-cosine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:05, 3421.53it/s]\n",
      "20000it [00:05, 3401.18it/s]\n",
      "20000it [00:05, 3431.71it/s]\n",
      "20000it [00:05, 3343.35it/s]\n",
      "20000it [00:05, 3460.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing algorithm item-cosine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:06, 3316.23it/s]\n",
      "20000it [00:05, 3410.82it/s]\n",
      "20000it [00:06, 3322.89it/s]\n",
      "20000it [00:05, 3430.33it/s]\n",
      "20000it [00:05, 3341.18it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'popularity': [[0.36924708377518656,\n",
       "   0.4965005302226948,\n",
       "   0.6152704135737019,\n",
       "   0.6426299045599162,\n",
       "   0.6292682926829279],\n",
       "  0.5505832449628855,\n",
       "  0.40544114481568705,\n",
       "  0.6957253451100839],\n",
       " 'useraverage': [[0.30604453870625714,\n",
       "   0.4305408271474029,\n",
       "   0.5321314952279973,\n",
       "   0.5520678685047737,\n",
       "   0.5474019088016986],\n",
       "  0.4736373276776259,\n",
       "  0.3419993013451059,\n",
       "  0.6052753540101459],\n",
       " 'user-cosine': [[0.37179215270413657,\n",
       "   0.503923647932133,\n",
       "   0.621633085896077,\n",
       "   0.6483563096500541,\n",
       "   0.6335100742311777],\n",
       "  0.5558430540827157,\n",
       "  0.40959849499983714,\n",
       "  0.7020876131655943],\n",
       " 'item-cosine': [[0.34316012725344736,\n",
       "   0.483563096500532,\n",
       "   0.6021208907741271,\n",
       "   0.6248144220572649,\n",
       "   0.6074231177094392],\n",
       "  0.5322163308589621,\n",
       "  0.3837005215009889,\n",
       "  0.6807321402169354]}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_patk.run(algorithm_instances, num_users, num_items,k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I4eEUjcOutaZ"
   },
   "outputs": [],
   "source": [
    "cv_patk = CrossValidation('R@K')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9SAuM2uJutcc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing algorithm popularity\n",
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:05, 3430.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:06, 3310.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:05, 3429.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:05, 3412.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:05, 3416.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing algorithm useraverage\n",
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:06, 3314.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:06, 3315.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:05, 3336.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:06, 3280.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:06, 3284.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing algorithm user-cosine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:05, 3421.28it/s]\n",
      "20000it [00:06, 3281.53it/s]\n",
      "20000it [00:05, 3449.26it/s]\n",
      "20000it [00:06, 3298.18it/s]\n",
      "20000it [00:05, 3440.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing algorithm item-cosine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:05, 3358.31it/s]\n",
      "20000it [00:05, 3418.78it/s]\n",
      "20000it [00:05, 3432.82it/s]\n",
      "20000it [00:05, 3378.12it/s]\n",
      "20000it [00:05, 3420.55it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'popularity': [[0.3466588624187514,\n",
       "   0.4274468698270901,\n",
       "   0.5269205125667804,\n",
       "   0.5518738761026849,\n",
       "   0.5674793185065369],\n",
       "  0.4840758878843688,\n",
       "  0.3671373629798323,\n",
       "  0.6010144127889052],\n",
       " 'useraverage': [[0.30505841002027845,\n",
       "   0.39554692074366876,\n",
       "   0.48030412192442223,\n",
       "   0.5045885853815734,\n",
       "   0.5211179870422066],\n",
       "  0.44132320502242983,\n",
       "  0.32931026359142457,\n",
       "  0.5533361464534351],\n",
       " 'user-cosine': [[0.34778041993806913,\n",
       "   0.4314035774468209,\n",
       "   0.5293633772333985,\n",
       "   0.5553818201403046,\n",
       "   0.5674144230096255],\n",
       "  0.4862687235536437,\n",
       "  0.3694473610987218,\n",
       "  0.6030900860085656],\n",
       " 'item-cosine': [[0.3277711938444533,\n",
       "   0.4237782250680911,\n",
       "   0.5191391022223312,\n",
       "   0.5448659224612776,\n",
       "   0.5593011306991799],\n",
       "  0.4749711148590666,\n",
       "  0.35357317503649865,\n",
       "  0.5963690546816346]}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_patk.run(algorithm_instances, num_users, num_items,k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NQy9Jc9rutft"
   },
   "source": [
    "Q4) Analysis:\n",
    "\n",
    "(A) \n",
    "For each of the metrics the three values are Average, Low CI and high CI.\n",
    "             Ave LowCI HIgh CI\n",
    "\n",
    "\n",
    "* RMSE {'item-cosine': [ 1.020, 1.006, 1.033,\n",
    "'popularity': [ 3.159, 3.139, 3.178,\n",
    "'user-cosine': [ 1.017, 1.009, 1.025,\n",
    "'useraverage': [ 1.043, 1.028, 1.058,}\n",
    "P@K\n",
    "{'item-cosine': [ 0.532, 0.383, 0.680,\n",
    "'popularity': [ 0.550, 0.405, 0.695,\n",
    "'user-cosine': [ 0.555, 0.409, 0.702,\n",
    "'useraverage': [ 0.473, 0.341, 0.605]}\n",
    "R@K\n",
    "{'item-cosine': [ 0.474, 0.353, 0.596],\n",
    "'popularity': [ 0.484, 0.367, 0.601,\n",
    "'user-cosine': [ 0.486, 0.369, 0.603,\n",
    "'useraverage': [ 0.441, 0.329, 0.553}\n",
    "\n",
    "\n",
    "\n",
    "(B)\n",
    "Some baselines cannot be evaluated with some metrics? Which ones and why?\n",
    "\n",
    "* For User Average This predicts the same average rating for all the movies for a user (for the movies there are no ratings). In this case rank based metrics P@k and R@k cannot be evaluated. For popularity, We cannot use RMSE for popularity becuase the popularity values in this case are between 0 to 1 (because we are not taking the exact rating for calculation we have only taken if the user liked(rating > 4) or not) but the test ratings are from 1 to 5. so RMSE cannot be evaluated\n",
    "\n",
    "\n",
    "\n",
    "(C)\n",
    "What is the best algorithm for each of RMSE, P@k, and R@k? Can you explain why this may be?\n",
    "\n",
    "* P@k and R@k the evaluations are based on ranking (we need to recommend most relavant to each user). For better ranking the similarity metrics are most suitable because the popularity and average are not persnolized to each user. From the results we can say that user cosine average performed slighlty better in both P@K and R@K. For RMSE cosine similarity measures work better becuase the similarity measures predict the rating based on ratings of most similar users or items. We can also see that in case of RMSE similarity measure have better performed.\n",
    "\n",
    "\n",
    "\n",
    "(D)\n",
    "Does good performance on RMSE imply good performance on ranking metrics and vice versa? Why / why not?\n",
    "\n",
    "* No good performance of RMSE doesn't imply good performace on ranking metrics. Becuase RMSE is calulated for all the user ratings wheter he liked it or not irrespective of their rankings. So good RMSE may come at expense of bad ranking of top K. Similarly, in case of ranking metrics we are only concerned about ranking in top k and have no clue about others. So good performance of ranking doesn't necasarily mean good performance of RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating Eculidean to know which is better\n",
    "item_cosine_recsys = SimBasedRecSys('item','euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8dt-cvDSvAyq"
   },
   "outputs": [],
   "source": [
    "user_cosine_recsys = SimBasedRecSys('user','euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VbikcUD7vA1Q"
   },
   "outputs": [],
   "source": [
    "# 1. gather your algorithms in previous steps.\n",
    "algorithm_instances = [user_cosine_recsys, item_cosine_recsys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H-6hlu1rvA37"
   },
   "outputs": [],
   "source": [
    "cv_patk = CrossValidation('RMSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jH0Pdt_4vA6F"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing algorithm user-euclidean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:05, 3393.29it/s]\n",
      "20000it [00:05, 3397.10it/s]\n",
      "20000it [00:06, 3247.34it/s]\n",
      "20000it [00:05, 3430.09it/s]\n",
      "20000it [00:06, 3323.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing algorithm item-euclidean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:05, 3412.78it/s]\n",
      "20000it [00:05, 3420.65it/s]\n",
      "20000it [00:06, 3239.82it/s]\n",
      "20000it [00:05, 3411.60it/s]\n",
      "20000it [00:06, 3289.98it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'user-euclidean': [[1.0319953645887305,\n",
       "   1.0272960502657182,\n",
       "   1.017739206917733,\n",
       "   1.0146850193650487,\n",
       "   1.0207231693447965],\n",
       "  1.0224877620964052,\n",
       "  1.0137065658920232,\n",
       "  1.0312689583007872],\n",
       " 'item-euclidean': [[1.0452460304884215,\n",
       "   1.0315283051917867,\n",
       "   1.0203644555365832,\n",
       "   1.0215306724762894,\n",
       "   1.023912278910453],\n",
       "  1.0285163485207067,\n",
       "  1.0157114777932958,\n",
       "  1.0413212192481176]}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_patk.run(algorithm_instances, num_users, num_items,k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hZwk-hp6vA9a"
   },
   "outputs": [],
   "source": [
    "user_cosine_recsys = SimBasedRecSys('user','euclidean')\n",
    "item_cosine_recsys = SimBasedRecSys('item','euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZRNKaZc_vaBh"
   },
   "outputs": [],
   "source": [
    "# 1. gather your algorithms in previous steps.\n",
    "algorithm_instances = [user_cosine_recsys, item_cosine_recsys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2kJ6sfebvaEF"
   },
   "outputs": [],
   "source": [
    "cv_patk = CrossValidation('RMSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vc40m9jqvaG7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing algorithm user-euclidean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:05, 3419.81it/s]\n",
      "20000it [00:05, 3411.26it/s]\n",
      "20000it [00:06, 3288.88it/s]\n",
      "20000it [00:06, 3266.17it/s]\n",
      "20000it [00:06, 3113.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing algorithm item-euclidean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:05, 3392.81it/s]\n",
      "20000it [00:05, 3421.34it/s]\n",
      "20000it [00:06, 3270.66it/s]\n",
      "20000it [00:05, 3410.89it/s]\n",
      "20000it [00:06, 3239.66it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'user-euclidean': [[1.0319953645887305,\n",
       "   1.0272960502657182,\n",
       "   1.017739206917733,\n",
       "   1.0146850193650487,\n",
       "   1.0207231693447965],\n",
       "  1.0224877620964052,\n",
       "  1.0137065658920232,\n",
       "  1.0312689583007872],\n",
       " 'item-euclidean': [[1.0452460304884215,\n",
       "   1.0315283051917867,\n",
       "   1.0203644555365832,\n",
       "   1.0215306724762894,\n",
       "   1.023912278910453],\n",
       "  1.0285163485207067,\n",
       "  1.0157114777932958,\n",
       "  1.0413212192481176]}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_patk.run(algorithm_instances, num_users, num_items,k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5nYfZWGWvaJU"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 3, 4, ..., 0, 0, 0],\n",
       "       [4, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [5, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 5, 0, ..., 0, 0, 0]], dtype=int8)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q5df = dataPreprocessor(rating_df, num_users, num_items)\n",
    "q5df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieID</th>\n",
       "      <th>movieTitle</th>\n",
       "      <th>releaseDate</th>\n",
       "      <th>videoReleaseDate</th>\n",
       "      <th>IMDbURL</th>\n",
       "      <th>unknown</th>\n",
       "      <th>action</th>\n",
       "      <th>adventure</th>\n",
       "      <th>animation</th>\n",
       "      <th>childrens</th>\n",
       "      <th>...</th>\n",
       "      <th>fantasy</th>\n",
       "      <th>filmNoir</th>\n",
       "      <th>horror</th>\n",
       "      <th>musical</th>\n",
       "      <th>mystery</th>\n",
       "      <th>romance</th>\n",
       "      <th>sciFi</th>\n",
       "      <th>thriller</th>\n",
       "      <th>war</th>\n",
       "      <th>western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Toy%20Story%2...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>GoldenEye (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?GoldenEye%20(...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Four Rooms (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Four%20Rooms%...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Get Shorty (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Get%20Shorty%...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Copycat (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Copycat%20(1995)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieID         movieTitle  releaseDate  videoReleaseDate  \\\n",
       "0        1   Toy Story (1995)  01-Jan-1995               NaN   \n",
       "1        2   GoldenEye (1995)  01-Jan-1995               NaN   \n",
       "2        3  Four Rooms (1995)  01-Jan-1995               NaN   \n",
       "3        4  Get Shorty (1995)  01-Jan-1995               NaN   \n",
       "4        5     Copycat (1995)  01-Jan-1995               NaN   \n",
       "\n",
       "                                             IMDbURL  unknown  action  \\\n",
       "0  http://us.imdb.com/M/title-exact?Toy%20Story%2...        0       0   \n",
       "1  http://us.imdb.com/M/title-exact?GoldenEye%20(...        0       1   \n",
       "2  http://us.imdb.com/M/title-exact?Four%20Rooms%...        0       0   \n",
       "3  http://us.imdb.com/M/title-exact?Get%20Shorty%...        0       1   \n",
       "4  http://us.imdb.com/M/title-exact?Copycat%20(1995)        0       0   \n",
       "\n",
       "   adventure  animation  childrens   ...     fantasy  filmNoir  horror  \\\n",
       "0          0          1          1   ...           0         0       0   \n",
       "1          1          0          0   ...           0         0       0   \n",
       "2          0          0          0   ...           0         0       0   \n",
       "3          0          0          0   ...           0         0       0   \n",
       "4          0          0          0   ...           0         0       0   \n",
       "\n",
       "   musical  mystery  romance  sciFi  thriller  war  western  \n",
       "0        0        0        0      0         0    0        0  \n",
       "1        0        0        0      0         1    0        0  \n",
       "2        0        0        0      0         1    0        0  \n",
       "3        0        0        0      0         0    0        0  \n",
       "4        0        0        0      0         1    0        0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fieldsMovies = ['movieID', 'movieTitle', 'releaseDate', 'videoReleaseDate', 'IMDbURL', 'unknown', 'action', 'adventure',\n",
    "          'animation', 'childrens', 'comedy', 'crime', 'documentary', 'drama', 'fantasy', 'filmNoir', 'horror',\n",
    "          'musical', 'mystery', 'romance','sciFi', 'thriller', 'war', 'western']\n",
    "moviesDF = pd.read_csv(os.path.join(path, 'u.item'), sep='|', names=fieldsMovies, encoding='latin-1')\n",
    "moviesDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "icFfconOvaOF"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieID</th>\n",
       "      <th>movieTitle</th>\n",
       "      <th>releaseDate</th>\n",
       "      <th>videoReleaseDate</th>\n",
       "      <th>IMDbURL</th>\n",
       "      <th>unknown</th>\n",
       "      <th>action</th>\n",
       "      <th>adventure</th>\n",
       "      <th>animation</th>\n",
       "      <th>childrens</th>\n",
       "      <th>...</th>\n",
       "      <th>fantasy</th>\n",
       "      <th>filmNoir</th>\n",
       "      <th>horror</th>\n",
       "      <th>musical</th>\n",
       "      <th>mystery</th>\n",
       "      <th>romance</th>\n",
       "      <th>sciFi</th>\n",
       "      <th>thriller</th>\n",
       "      <th>war</th>\n",
       "      <th>western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1100</th>\n",
       "      <td>1101</td>\n",
       "      <td>Six Degrees of Separation (1993)</td>\n",
       "      <td>01-Jan-1993</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Six%20Degrees...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1101</th>\n",
       "      <td>1102</td>\n",
       "      <td>Two Much (1996)</td>\n",
       "      <td>01-Jan-1996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Two%20Much%20...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1102</th>\n",
       "      <td>1103</td>\n",
       "      <td>Trust (1990)</td>\n",
       "      <td>01-Jan-1990</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/Title?Trust+(1990)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1103</th>\n",
       "      <td>1104</td>\n",
       "      <td>C'est arriv prs de chez vous (1992)</td>\n",
       "      <td>01-Jan-1992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?C%27est%20arr...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1104</th>\n",
       "      <td>1105</td>\n",
       "      <td>Firestorm (1998)</td>\n",
       "      <td>09-Jan-1998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?imdb-title-12...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1105</th>\n",
       "      <td>1106</td>\n",
       "      <td>Newton Boys, The (1998)</td>\n",
       "      <td>14-Mar-1998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/Title?Newton+Boys,+The+(1998)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1106</th>\n",
       "      <td>1107</td>\n",
       "      <td>Beyond Rangoon (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Beyond%20Rang...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1107</th>\n",
       "      <td>1108</td>\n",
       "      <td>Feast of July (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Feast%20of%20...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108</th>\n",
       "      <td>1109</td>\n",
       "      <td>Death and the Maiden (1994)</td>\n",
       "      <td>01-Jan-1994</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Death%20and%2...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1109</th>\n",
       "      <td>1110</td>\n",
       "      <td>Tank Girl (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Tank%20Girl%2...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1110</th>\n",
       "      <td>1111</td>\n",
       "      <td>Double Happiness (1994)</td>\n",
       "      <td>01-Mar-1996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Double%20Happ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1111</th>\n",
       "      <td>1112</td>\n",
       "      <td>Cobb (1994)</td>\n",
       "      <td>01-Jan-1994</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Cobb%20(1994)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1112</th>\n",
       "      <td>1113</td>\n",
       "      <td>Mrs. Parker and the Vicious Circle (1994)</td>\n",
       "      <td>01-Jan-1994</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Mrs.%20Parker...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1113</th>\n",
       "      <td>1114</td>\n",
       "      <td>Faithful (1996)</td>\n",
       "      <td>03-Apr-1996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Faithful%20(1...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114</th>\n",
       "      <td>1115</td>\n",
       "      <td>Twelfth Night (1996)</td>\n",
       "      <td>25-Oct-1996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Twelfth%20Nig...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1115</th>\n",
       "      <td>1116</td>\n",
       "      <td>Mark of Zorro, The (1940)</td>\n",
       "      <td>01-Jan-1940</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Mark%20of%20Z...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1116</th>\n",
       "      <td>1117</td>\n",
       "      <td>Surviving Picasso (1996)</td>\n",
       "      <td>20-Sep-1996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Surviving%20P...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1117</th>\n",
       "      <td>1118</td>\n",
       "      <td>Up in Smoke (1978)</td>\n",
       "      <td>01-Jan-1978</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Up%20in%20Smo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118</th>\n",
       "      <td>1119</td>\n",
       "      <td>Some Kind of Wonderful (1987)</td>\n",
       "      <td>01-Jan-1987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Some%20Kind%2...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1119</th>\n",
       "      <td>1120</td>\n",
       "      <td>I'm Not Rappaport (1996)</td>\n",
       "      <td>13-Nov-1996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?I'm%20Not%20R...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1120</th>\n",
       "      <td>1121</td>\n",
       "      <td>Umbrellas of Cherbourg, The (Parapluies de Che...</td>\n",
       "      <td>05-Apr-1996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Parapluies%20...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1121</th>\n",
       "      <td>1122</td>\n",
       "      <td>They Made Me a Criminal (1939)</td>\n",
       "      <td>01-Jan-1939</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?They%20Made%2...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1122</th>\n",
       "      <td>1123</td>\n",
       "      <td>Last Time I Saw Paris, The (1954)</td>\n",
       "      <td>01-Jan-1954</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Last%20Time%2...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123</th>\n",
       "      <td>1124</td>\n",
       "      <td>Farewell to Arms, A (1932)</td>\n",
       "      <td>01-Jan-1932</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Farewell%20to...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1124</th>\n",
       "      <td>1125</td>\n",
       "      <td>Innocents, The (1961)</td>\n",
       "      <td>01-Jan-1961</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Innocents,%20...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1125</th>\n",
       "      <td>1126</td>\n",
       "      <td>Old Man and the Sea, The (1958)</td>\n",
       "      <td>01-Jan-1958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Old%20Man%20a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>1127</td>\n",
       "      <td>Truman Show, The (1998)</td>\n",
       "      <td>01-Jan-1998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/Title?Truman+Show,+The+(1998)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1127</th>\n",
       "      <td>1128</td>\n",
       "      <td>Heidi Fleiss: Hollywood Madam (1995)</td>\n",
       "      <td>09-Feb-1996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Heidi%20Fleis...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1128</th>\n",
       "      <td>1129</td>\n",
       "      <td>Chungking Express (1994)</td>\n",
       "      <td>16-Feb-1996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Chongqing%20S...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1129</th>\n",
       "      <td>1130</td>\n",
       "      <td>Jupiter's Wife (1994)</td>\n",
       "      <td>09-Feb-1996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Jupiter's%20W...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1270</th>\n",
       "      <td>1271</td>\n",
       "      <td>North (1994)</td>\n",
       "      <td>01-Jan-1994</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?North%20(1994)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271</th>\n",
       "      <td>1272</td>\n",
       "      <td>Talking About Sex (1994)</td>\n",
       "      <td>01-Jan-1994</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Talking%20Abo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1272</th>\n",
       "      <td>1273</td>\n",
       "      <td>Color of Night (1994)</td>\n",
       "      <td>01-Jan-1994</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Color%20of%20...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1273</th>\n",
       "      <td>1274</td>\n",
       "      <td>Robocop 3 (1993)</td>\n",
       "      <td>01-Jan-1993</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Robocop%203%2...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274</th>\n",
       "      <td>1275</td>\n",
       "      <td>Killer (Bulletproof Heart) (1994)</td>\n",
       "      <td>01-Jan-1994</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Killer%20(1994)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1275</th>\n",
       "      <td>1276</td>\n",
       "      <td>Sunset Park (1996)</td>\n",
       "      <td>26-Apr-1996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Sunset%20Park...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1276</th>\n",
       "      <td>1277</td>\n",
       "      <td>Set It Off (1996)</td>\n",
       "      <td>25-Sep-1996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Set%20It%20Of...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1277</th>\n",
       "      <td>1278</td>\n",
       "      <td>Selena (1997)</td>\n",
       "      <td>21-Mar-1997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Selena%20(1997)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1278</th>\n",
       "      <td>1279</td>\n",
       "      <td>Wild America (1997)</td>\n",
       "      <td>04-Jul-1997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Wild+America+...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1279</th>\n",
       "      <td>1280</td>\n",
       "      <td>Gang Related (1997)</td>\n",
       "      <td>01-Jan-1997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Gang+Related+...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1280</th>\n",
       "      <td>1281</td>\n",
       "      <td>Manny &amp; Lo (1996)</td>\n",
       "      <td>26-Jul-1996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Manny%20&amp;%20L...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1281</th>\n",
       "      <td>1282</td>\n",
       "      <td>Grass Harp, The (1995)</td>\n",
       "      <td>11-Oct-1996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Grass%20Harp,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1282</th>\n",
       "      <td>1283</td>\n",
       "      <td>Out to Sea (1997)</td>\n",
       "      <td>04-Jul-1997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Out+to+Sea+(1...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1283</th>\n",
       "      <td>1284</td>\n",
       "      <td>Before and After (1996)</td>\n",
       "      <td>23-Feb-1996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Before%20and%...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1284</th>\n",
       "      <td>1285</td>\n",
       "      <td>Princess Caraboo (1994)</td>\n",
       "      <td>01-Jan-1994</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Princess%20Ca...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1285</th>\n",
       "      <td>1286</td>\n",
       "      <td>Shall We Dance? (1937)</td>\n",
       "      <td>01-Jan-1937</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Shall%20We%20...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1286</th>\n",
       "      <td>1287</td>\n",
       "      <td>Ed (1996)</td>\n",
       "      <td>08-Mar-1996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Ed%20(1996)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1287</th>\n",
       "      <td>1288</td>\n",
       "      <td>Denise Calls Up (1995)</td>\n",
       "      <td>29-Mar-1996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Denise%20Call...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1288</th>\n",
       "      <td>1289</td>\n",
       "      <td>Jack and Sarah (1995)</td>\n",
       "      <td>22-Mar-1996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Jack%20and%20...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1289</th>\n",
       "      <td>1290</td>\n",
       "      <td>Country Life (1994)</td>\n",
       "      <td>01-Jan-1994</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Country%20Lif...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1290</th>\n",
       "      <td>1291</td>\n",
       "      <td>Celtic Pride (1996)</td>\n",
       "      <td>19-Apr-1996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Celtic%20Prid...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1291</th>\n",
       "      <td>1292</td>\n",
       "      <td>Simple Wish, A (1997)</td>\n",
       "      <td>11-Jul-1997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Simple+Wish%2...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1292</th>\n",
       "      <td>1293</td>\n",
       "      <td>Star Kid (1997)</td>\n",
       "      <td>16-Jan-1998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?imdb-title-12...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1293</th>\n",
       "      <td>1294</td>\n",
       "      <td>Ayn Rand: A Sense of Life (1997)</td>\n",
       "      <td>13-Feb-1998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/Title?Ayn+Rand%3A+A+Sense+o...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>1295</td>\n",
       "      <td>Kicked in the Head (1997)</td>\n",
       "      <td>01-Jan-1997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Kicked+in+the...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1295</th>\n",
       "      <td>1296</td>\n",
       "      <td>Indian Summer (1996)</td>\n",
       "      <td>01-Jan-1996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Indian+Summer...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296</th>\n",
       "      <td>1297</td>\n",
       "      <td>Love Affair (1994)</td>\n",
       "      <td>01-Jan-1994</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Love%20Affair...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1297</th>\n",
       "      <td>1298</td>\n",
       "      <td>Band Wagon, The (1953)</td>\n",
       "      <td>01-Jan-1953</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Band%20Wagon,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1298</th>\n",
       "      <td>1299</td>\n",
       "      <td>Penny Serenade (1941)</td>\n",
       "      <td>01-Jan-1941</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Penny%20Seren...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299</th>\n",
       "      <td>1300</td>\n",
       "      <td>'Til There Was You (1997)</td>\n",
       "      <td>30-May-1997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/Title?%27Til+There+Was+You+...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows  24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      movieID                                         movieTitle  releaseDate  \\\n",
       "1100     1101                   Six Degrees of Separation (1993)  01-Jan-1993   \n",
       "1101     1102                                    Two Much (1996)  01-Jan-1996   \n",
       "1102     1103                                       Trust (1990)  01-Jan-1990   \n",
       "1103     1104              C'est arriv prs de chez vous (1992)  01-Jan-1992   \n",
       "1104     1105                                   Firestorm (1998)  09-Jan-1998   \n",
       "1105     1106                            Newton Boys, The (1998)  14-Mar-1998   \n",
       "1106     1107                              Beyond Rangoon (1995)  01-Jan-1995   \n",
       "1107     1108                               Feast of July (1995)  01-Jan-1995   \n",
       "1108     1109                        Death and the Maiden (1994)  01-Jan-1994   \n",
       "1109     1110                                   Tank Girl (1995)  01-Jan-1995   \n",
       "1110     1111                            Double Happiness (1994)  01-Mar-1996   \n",
       "1111     1112                                        Cobb (1994)  01-Jan-1994   \n",
       "1112     1113          Mrs. Parker and the Vicious Circle (1994)  01-Jan-1994   \n",
       "1113     1114                                    Faithful (1996)  03-Apr-1996   \n",
       "1114     1115                               Twelfth Night (1996)  25-Oct-1996   \n",
       "1115     1116                          Mark of Zorro, The (1940)  01-Jan-1940   \n",
       "1116     1117                           Surviving Picasso (1996)  20-Sep-1996   \n",
       "1117     1118                                 Up in Smoke (1978)  01-Jan-1978   \n",
       "1118     1119                      Some Kind of Wonderful (1987)  01-Jan-1987   \n",
       "1119     1120                           I'm Not Rappaport (1996)  13-Nov-1996   \n",
       "1120     1121  Umbrellas of Cherbourg, The (Parapluies de Che...  05-Apr-1996   \n",
       "1121     1122                     They Made Me a Criminal (1939)  01-Jan-1939   \n",
       "1122     1123                  Last Time I Saw Paris, The (1954)  01-Jan-1954   \n",
       "1123     1124                         Farewell to Arms, A (1932)  01-Jan-1932   \n",
       "1124     1125                              Innocents, The (1961)  01-Jan-1961   \n",
       "1125     1126                    Old Man and the Sea, The (1958)  01-Jan-1958   \n",
       "1126     1127                            Truman Show, The (1998)  01-Jan-1998   \n",
       "1127     1128              Heidi Fleiss: Hollywood Madam (1995)   09-Feb-1996   \n",
       "1128     1129                           Chungking Express (1994)  16-Feb-1996   \n",
       "1129     1130                              Jupiter's Wife (1994)  09-Feb-1996   \n",
       "...       ...                                                ...          ...   \n",
       "1270     1271                                       North (1994)  01-Jan-1994   \n",
       "1271     1272                           Talking About Sex (1994)  01-Jan-1994   \n",
       "1272     1273                              Color of Night (1994)  01-Jan-1994   \n",
       "1273     1274                                   Robocop 3 (1993)  01-Jan-1993   \n",
       "1274     1275                  Killer (Bulletproof Heart) (1994)  01-Jan-1994   \n",
       "1275     1276                                 Sunset Park (1996)  26-Apr-1996   \n",
       "1276     1277                                  Set It Off (1996)  25-Sep-1996   \n",
       "1277     1278                                      Selena (1997)  21-Mar-1997   \n",
       "1278     1279                                Wild America (1997)  04-Jul-1997   \n",
       "1279     1280                                Gang Related (1997)  01-Jan-1997   \n",
       "1280     1281                                  Manny & Lo (1996)  26-Jul-1996   \n",
       "1281     1282                             Grass Harp, The (1995)  11-Oct-1996   \n",
       "1282     1283                                  Out to Sea (1997)  04-Jul-1997   \n",
       "1283     1284                            Before and After (1996)  23-Feb-1996   \n",
       "1284     1285                            Princess Caraboo (1994)  01-Jan-1994   \n",
       "1285     1286                             Shall We Dance? (1937)  01-Jan-1937   \n",
       "1286     1287                                          Ed (1996)  08-Mar-1996   \n",
       "1287     1288                             Denise Calls Up (1995)  29-Mar-1996   \n",
       "1288     1289                              Jack and Sarah (1995)  22-Mar-1996   \n",
       "1289     1290                                Country Life (1994)  01-Jan-1994   \n",
       "1290     1291                                Celtic Pride (1996)  19-Apr-1996   \n",
       "1291     1292                              Simple Wish, A (1997)  11-Jul-1997   \n",
       "1292     1293                                    Star Kid (1997)  16-Jan-1998   \n",
       "1293     1294                   Ayn Rand: A Sense of Life (1997)  13-Feb-1998   \n",
       "1294     1295                          Kicked in the Head (1997)  01-Jan-1997   \n",
       "1295     1296                               Indian Summer (1996)  01-Jan-1996   \n",
       "1296     1297                                 Love Affair (1994)  01-Jan-1994   \n",
       "1297     1298                             Band Wagon, The (1953)  01-Jan-1953   \n",
       "1298     1299                              Penny Serenade (1941)  01-Jan-1941   \n",
       "1299     1300                          'Til There Was You (1997)  30-May-1997   \n",
       "\n",
       "      videoReleaseDate                                            IMDbURL  \\\n",
       "1100               NaN  http://us.imdb.com/M/title-exact?Six%20Degrees...   \n",
       "1101               NaN  http://us.imdb.com/M/title-exact?Two%20Much%20...   \n",
       "1102               NaN              http://us.imdb.com/Title?Trust+(1990)   \n",
       "1103               NaN  http://us.imdb.com/M/title-exact?C%27est%20arr...   \n",
       "1104               NaN  http://us.imdb.com/M/title-exact?imdb-title-12...   \n",
       "1105               NaN   http://us.imdb.com/Title?Newton+Boys,+The+(1998)   \n",
       "1106               NaN  http://us.imdb.com/M/title-exact?Beyond%20Rang...   \n",
       "1107               NaN  http://us.imdb.com/M/title-exact?Feast%20of%20...   \n",
       "1108               NaN  http://us.imdb.com/M/title-exact?Death%20and%2...   \n",
       "1109               NaN  http://us.imdb.com/M/title-exact?Tank%20Girl%2...   \n",
       "1110               NaN  http://us.imdb.com/M/title-exact?Double%20Happ...   \n",
       "1111               NaN     http://us.imdb.com/M/title-exact?Cobb%20(1994)   \n",
       "1112               NaN  http://us.imdb.com/M/title-exact?Mrs.%20Parker...   \n",
       "1113               NaN  http://us.imdb.com/M/title-exact?Faithful%20(1...   \n",
       "1114               NaN  http://us.imdb.com/M/title-exact?Twelfth%20Nig...   \n",
       "1115               NaN  http://us.imdb.com/M/title-exact?Mark%20of%20Z...   \n",
       "1116               NaN  http://us.imdb.com/M/title-exact?Surviving%20P...   \n",
       "1117               NaN  http://us.imdb.com/M/title-exact?Up%20in%20Smo...   \n",
       "1118               NaN  http://us.imdb.com/M/title-exact?Some%20Kind%2...   \n",
       "1119               NaN  http://us.imdb.com/M/title-exact?I'm%20Not%20R...   \n",
       "1120               NaN  http://us.imdb.com/M/title-exact?Parapluies%20...   \n",
       "1121               NaN  http://us.imdb.com/M/title-exact?They%20Made%2...   \n",
       "1122               NaN  http://us.imdb.com/M/title-exact?Last%20Time%2...   \n",
       "1123               NaN  http://us.imdb.com/M/title-exact?Farewell%20to...   \n",
       "1124               NaN  http://us.imdb.com/M/title-exact?Innocents,%20...   \n",
       "1125               NaN  http://us.imdb.com/M/title-exact?Old%20Man%20a...   \n",
       "1126               NaN   http://us.imdb.com/Title?Truman+Show,+The+(1998)   \n",
       "1127               NaN  http://us.imdb.com/M/title-exact?Heidi%20Fleis...   \n",
       "1128               NaN  http://us.imdb.com/M/title-exact?Chongqing%20S...   \n",
       "1129               NaN  http://us.imdb.com/M/title-exact?Jupiter's%20W...   \n",
       "...                ...                                                ...   \n",
       "1270               NaN    http://us.imdb.com/M/title-exact?North%20(1994)   \n",
       "1271               NaN  http://us.imdb.com/M/title-exact?Talking%20Abo...   \n",
       "1272               NaN  http://us.imdb.com/M/title-exact?Color%20of%20...   \n",
       "1273               NaN  http://us.imdb.com/M/title-exact?Robocop%203%2...   \n",
       "1274               NaN   http://us.imdb.com/M/title-exact?Killer%20(1994)   \n",
       "1275               NaN  http://us.imdb.com/M/title-exact?Sunset%20Park...   \n",
       "1276               NaN  http://us.imdb.com/M/title-exact?Set%20It%20Of...   \n",
       "1277               NaN   http://us.imdb.com/M/title-exact?Selena%20(1997)   \n",
       "1278               NaN  http://us.imdb.com/M/title-exact?Wild+America+...   \n",
       "1279               NaN  http://us.imdb.com/M/title-exact?Gang+Related+...   \n",
       "1280               NaN  http://us.imdb.com/M/title-exact?Manny%20&%20L...   \n",
       "1281               NaN  http://us.imdb.com/M/title-exact?Grass%20Harp,...   \n",
       "1282               NaN  http://us.imdb.com/M/title-exact?Out+to+Sea+(1...   \n",
       "1283               NaN  http://us.imdb.com/M/title-exact?Before%20and%...   \n",
       "1284               NaN  http://us.imdb.com/M/title-exact?Princess%20Ca...   \n",
       "1285               NaN  http://us.imdb.com/M/title-exact?Shall%20We%20...   \n",
       "1286               NaN       http://us.imdb.com/M/title-exact?Ed%20(1996)   \n",
       "1287               NaN  http://us.imdb.com/M/title-exact?Denise%20Call...   \n",
       "1288               NaN  http://us.imdb.com/M/title-exact?Jack%20and%20...   \n",
       "1289               NaN  http://us.imdb.com/M/title-exact?Country%20Lif...   \n",
       "1290               NaN  http://us.imdb.com/M/title-exact?Celtic%20Prid...   \n",
       "1291               NaN  http://us.imdb.com/M/title-exact?Simple+Wish%2...   \n",
       "1292               NaN  http://us.imdb.com/M/title-exact?imdb-title-12...   \n",
       "1293               NaN  http://us.imdb.com/Title?Ayn+Rand%3A+A+Sense+o...   \n",
       "1294               NaN  http://us.imdb.com/M/title-exact?Kicked+in+the...   \n",
       "1295               NaN  http://us.imdb.com/M/title-exact?Indian+Summer...   \n",
       "1296               NaN  http://us.imdb.com/M/title-exact?Love%20Affair...   \n",
       "1297               NaN  http://us.imdb.com/M/title-exact?Band%20Wagon,...   \n",
       "1298               NaN  http://us.imdb.com/M/title-exact?Penny%20Seren...   \n",
       "1299               NaN  http://us.imdb.com/Title?%27Til+There+Was+You+...   \n",
       "\n",
       "      unknown  action  adventure  animation  childrens   ...     fantasy  \\\n",
       "1100        0       0          0          0          0   ...           0   \n",
       "1101        0       0          0          0          0   ...           0   \n",
       "1102        0       0          0          0          0   ...           0   \n",
       "1103        0       0          0          0          0   ...           0   \n",
       "1104        0       1          1          0          0   ...           0   \n",
       "1105        0       0          0          0          0   ...           0   \n",
       "1106        0       0          0          0          0   ...           0   \n",
       "1107        0       0          0          0          0   ...           0   \n",
       "1108        0       0          0          0          0   ...           0   \n",
       "1109        0       1          0          0          0   ...           0   \n",
       "1110        0       0          0          0          0   ...           0   \n",
       "1111        0       0          0          0          0   ...           0   \n",
       "1112        0       0          0          0          0   ...           0   \n",
       "1113        0       0          0          0          0   ...           0   \n",
       "1114        0       0          0          0          0   ...           0   \n",
       "1115        0       0          1          0          0   ...           0   \n",
       "1116        0       0          0          0          0   ...           0   \n",
       "1117        0       0          0          0          0   ...           0   \n",
       "1118        0       0          0          0          0   ...           0   \n",
       "1119        0       0          0          0          0   ...           0   \n",
       "1120        0       0          0          0          0   ...           0   \n",
       "1121        0       0          0          0          0   ...           0   \n",
       "1122        0       0          0          0          0   ...           0   \n",
       "1123        0       0          0          0          0   ...           0   \n",
       "1124        0       0          0          0          0   ...           0   \n",
       "1125        0       0          1          0          0   ...           0   \n",
       "1126        0       0          0          0          0   ...           0   \n",
       "1127        0       0          0          0          0   ...           0   \n",
       "1128        0       0          0          0          0   ...           0   \n",
       "1129        0       0          0          0          0   ...           0   \n",
       "...       ...     ...        ...        ...        ...   ...         ...   \n",
       "1270        0       0          0          0          0   ...           0   \n",
       "1271        0       0          0          0          0   ...           0   \n",
       "1272        0       0          0          0          0   ...           0   \n",
       "1273        0       0          0          0          0   ...           0   \n",
       "1274        0       0          0          0          0   ...           0   \n",
       "1275        0       0          0          0          0   ...           0   \n",
       "1276        0       1          0          0          0   ...           0   \n",
       "1277        0       0          0          0          0   ...           0   \n",
       "1278        0       0          1          0          1   ...           0   \n",
       "1279        0       0          0          0          0   ...           0   \n",
       "1280        0       0          0          0          0   ...           0   \n",
       "1281        0       0          0          0          0   ...           0   \n",
       "1282        0       0          0          0          0   ...           0   \n",
       "1283        0       0          0          0          0   ...           0   \n",
       "1284        0       0          0          0          0   ...           0   \n",
       "1285        0       0          0          0          0   ...           0   \n",
       "1286        0       0          0          0          0   ...           0   \n",
       "1287        0       0          0          0          0   ...           0   \n",
       "1288        0       0          0          0          0   ...           0   \n",
       "1289        0       0          0          0          0   ...           0   \n",
       "1290        0       0          0          0          0   ...           0   \n",
       "1291        0       0          0          0          1   ...           1   \n",
       "1292        0       0          1          0          1   ...           1   \n",
       "1293        0       0          0          0          0   ...           0   \n",
       "1294        0       0          0          0          0   ...           0   \n",
       "1295        0       0          0          0          0   ...           0   \n",
       "1296        0       0          0          0          0   ...           0   \n",
       "1297        0       0          0          0          0   ...           0   \n",
       "1298        0       0          0          0          0   ...           0   \n",
       "1299        0       0          0          0          0   ...           0   \n",
       "\n",
       "      filmNoir  horror  musical  mystery  romance  sciFi  thriller  war  \\\n",
       "1100         0       0        0        1        0      0         0    0   \n",
       "1101         0       0        0        0        1      0         0    0   \n",
       "1102         0       0        0        0        0      0         0    0   \n",
       "1103         0       0        0        0        0      0         0    0   \n",
       "1104         0       0        0        0        0      0         1    0   \n",
       "1105         0       0        0        0        0      0         0    0   \n",
       "1106         0       0        0        0        0      0         0    0   \n",
       "1107         0       0        0        0        0      0         0    0   \n",
       "1108         0       0        0        0        0      0         1    0   \n",
       "1109         0       0        1        0        0      1         0    0   \n",
       "1110         0       0        0        0        0      0         0    0   \n",
       "1111         0       0        0        0        0      0         0    0   \n",
       "1112         0       0        0        0        0      0         0    0   \n",
       "1113         0       0        0        0        0      0         0    0   \n",
       "1114         0       0        0        0        1      0         0    0   \n",
       "1115         0       0        0        0        0      0         0    0   \n",
       "1116         0       0        0        0        0      0         0    0   \n",
       "1117         0       0        0        0        0      0         0    0   \n",
       "1118         0       0        0        0        1      0         0    0   \n",
       "1119         0       0        0        0        0      0         0    0   \n",
       "1120         0       0        1        0        0      0         0    0   \n",
       "1121         0       0        0        0        0      0         0    0   \n",
       "1122         0       0        0        0        0      0         0    0   \n",
       "1123         0       0        0        0        1      0         0    1   \n",
       "1124         0       0        0        0        0      0         1    0   \n",
       "1125         0       0        0        0        0      0         0    0   \n",
       "1126         0       0        0        0        0      0         0    0   \n",
       "1127         0       0        0        0        0      0         0    0   \n",
       "1128         0       0        0        1        1      0         0    0   \n",
       "1129         0       0        0        0        0      0         0    0   \n",
       "...        ...     ...      ...      ...      ...    ...       ...  ...   \n",
       "1270         0       0        0        0        0      0         0    0   \n",
       "1271         0       0        0        0        0      0         0    0   \n",
       "1272         0       0        0        0        0      0         1    0   \n",
       "1273         0       0        0        0        0      1         1    0   \n",
       "1274         0       0        0        0        0      0         1    0   \n",
       "1275         0       0        0        0        0      0         0    0   \n",
       "1276         0       0        0        0        0      0         0    0   \n",
       "1277         0       0        1        0        0      0         0    0   \n",
       "1278         0       0        0        0        0      0         0    0   \n",
       "1279         0       0        0        0        0      0         0    0   \n",
       "1280         0       0        0        0        0      0         0    0   \n",
       "1281         0       0        0        0        0      0         0    0   \n",
       "1282         0       0        0        0        0      0         0    0   \n",
       "1283         0       0        0        1        0      0         0    0   \n",
       "1284         0       0        0        0        0      0         0    0   \n",
       "1285         0       0        1        0        1      0         0    0   \n",
       "1286         0       0        0        0        0      0         0    0   \n",
       "1287         0       0        0        0        0      0         0    0   \n",
       "1288         0       0        0        0        1      0         0    0   \n",
       "1289         0       0        0        0        1      0         0    0   \n",
       "1290         0       0        0        0        0      0         0    0   \n",
       "1291         0       0        0        0        0      0         0    0   \n",
       "1292         0       0        0        0        0      1         0    0   \n",
       "1293         0       0        0        0        0      0         0    0   \n",
       "1294         0       0        0        0        0      0         0    0   \n",
       "1295         0       0        0        0        0      0         0    0   \n",
       "1296         0       0        0        0        1      0         0    0   \n",
       "1297         0       0        1        0        0      0         0    0   \n",
       "1298         0       0        0        0        1      0         0    0   \n",
       "1299         0       0        0        0        1      0         0    0   \n",
       "\n",
       "      western  \n",
       "1100        0  \n",
       "1101        0  \n",
       "1102        0  \n",
       "1103        0  \n",
       "1104        0  \n",
       "1105        0  \n",
       "1106        0  \n",
       "1107        0  \n",
       "1108        0  \n",
       "1109        0  \n",
       "1110        0  \n",
       "1111        0  \n",
       "1112        0  \n",
       "1113        0  \n",
       "1114        0  \n",
       "1115        0  \n",
       "1116        0  \n",
       "1117        0  \n",
       "1118        0  \n",
       "1119        0  \n",
       "1120        0  \n",
       "1121        0  \n",
       "1122        0  \n",
       "1123        0  \n",
       "1124        0  \n",
       "1125        0  \n",
       "1126        0  \n",
       "1127        0  \n",
       "1128        0  \n",
       "1129        0  \n",
       "...       ...  \n",
       "1270        0  \n",
       "1271        0  \n",
       "1272        0  \n",
       "1273        0  \n",
       "1274        0  \n",
       "1275        0  \n",
       "1276        0  \n",
       "1277        0  \n",
       "1278        0  \n",
       "1279        0  \n",
       "1280        0  \n",
       "1281        0  \n",
       "1282        0  \n",
       "1283        0  \n",
       "1284        0  \n",
       "1285        0  \n",
       "1286        0  \n",
       "1287        0  \n",
       "1288        0  \n",
       "1289        0  \n",
       "1290        0  \n",
       "1291        0  \n",
       "1292        0  \n",
       "1293        0  \n",
       "1294        0  \n",
       "1295        0  \n",
       "1296        0  \n",
       "1297        0  \n",
       "1298        0  \n",
       "1299        0  \n",
       "\n",
       "[200 rows x 24 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moviesDF[1100:1300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UoUPHcsqvaRV"
   },
   "outputs": [],
   "source": [
    "listindex = [109,223,526,873,1298]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "49geJ0cXy9o7"
   },
   "outputs": [],
   "source": [
    "listmovieid = [110,224,527,874,1299]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TsX408vry9rc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.40238218, 0.33024479, ..., 0.        , 0.04718307,\n",
       "        0.04718307],\n",
       "       [0.40238218, 1.        , 0.27306918, ..., 0.        , 0.07829936,\n",
       "        0.07829936],\n",
       "       [0.33024479, 0.27306918, 1.        , ..., 0.        , 0.        ,\n",
       "        0.09687505],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.04718307, 0.07829936, 0.        , ..., 0.        , 1.        ,\n",
       "        0.        ],\n",
       "       [0.04718307, 0.07829936, 0.09687505, ..., 0.        , 0.        ,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainSet = q5df\n",
    "trainSet = trainSet.transpose()  \n",
    "uu_similarity = 1 - pairwise_distances(trainSet, metric='cosine')\n",
    "uu_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4xzRNka1y9wm"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 404,  116,  120,  180,   49,    0],\n",
       "       [  61,  402,  384,  160,  232,    1],\n",
       "       [ 249,   32,   41,  762,  409,    2],\n",
       "       ...,\n",
       "       [ 909, 1430, 1394, 1677, 1678, 1679],\n",
       "       [1405, 1422, 1621, 1350, 1671, 1680],\n",
       "       [ 556,  592, 1596, 1334,  766, 1681]], dtype=int64)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final = np.argsort(uu_similarity, axis=1, kind='quicksort', order=None)[:,1676:1682]\n",
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mIJpfeVGy9zI"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Operation Dumbo Drop (1995)'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listmovieid = [110,224,527,874,1299]\n",
    "listindex = [109,223,526,873,1298]\n",
    "moviesDF.iloc[109,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k_3GZ8Efy92h"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top similar movies to\n",
      "Operation Dumbo Drop (1995)\n",
      "are\n",
      "Corrina, Corrina (1994)\n",
      "Made in America (1993)\n",
      "Santa Clause, The (1994)\n",
      "Angels in the Outfield (1994)\n",
      "Junior (1994)\n",
      "Operation Dumbo Drop (1995)\n",
      "\n",
      "\n",
      "Top similar movies to\n",
      "Ridicule (1996)\n",
      "are\n",
      "Looking for Richard (1996)\n",
      "Horseman on the Roof, The (Hussard sur le toit, Le) (1995)\n",
      "Big Night (1996)\n",
      "Little Odessa (1994)\n",
      "Cold Comfort Farm (1995)\n",
      "Ridicule (1996)\n",
      "\n",
      "\n",
      "Top similar movies to\n",
      "Gandhi (1982)\n",
      "are\n",
      "Casablanca (1942)\n",
      "Raiders of the Lost Ark (1981)\n",
      "Forrest Gump (1994)\n",
      "One Flew Over the Cuckoo's Nest (1975)\n",
      "Amadeus (1984)\n",
      "Gandhi (1982)\n",
      "\n",
      "\n",
      "Top similar movies to\n",
      "Career Girls (1997)\n",
      "are\n",
      "In the Company of Men (1997)\n",
      "Ice Storm, The (1997)\n",
      "Ulee's Gold (1997)\n",
      "Kicked in the Head (1997)\n",
      "Steel (1997)\n",
      "Career Girls (1997)\n",
      "\n",
      "\n",
      "Top similar movies to\n",
      "Penny Serenade (1941)\n",
      "are\n",
      "Love in the Afternoon (1957)\n",
      "Laura (1944)\n",
      "Band Wagon, The (1953)\n",
      "Gay Divorcee, The (1934)\n",
      "Charade (1963)\n",
      "Penny Serenade (1941)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in listindex:\n",
    "    movielist = final[i]\n",
    "    print(\"Top similar movies to\")\n",
    "    print(moviesDF.iloc[i,1])\n",
    "    print(\"are\")\n",
    "\n",
    "    for j in movielist:\n",
    "        print(moviesDF.iloc[j,1])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5B\n",
    "\n",
    "If group of items are similar it means their item vectors are similar. This happens when same user ranked all of the items.\n",
    "In this case the magnitude of their rating doesn't matter becuase we are using cosine metric. only thing which matters if the same users have rated the items or not. For this to happen there could be many reasons like all the movies belonging to a particular genre or all of them have same actor, genre or director.\n",
    "\n",
    "Justify : \n",
    "Top similar movies to Career Girls (1997)\n",
    "are In the Company of Men (1997)\n",
    "Ice Storm, The (1997)\n",
    "Ulee's Gold (1997)\n",
    "Kicked in the Head (1997)\n",
    "Steel (1997)\n",
    "Career Girls (1997)\n",
    "\n",
    "All of them have same genre \"DRAMA\" and all of them are released in same year. In fact the movies all released in same year. So DRAMA lovers of 1990's must have rated all the movies.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "q6df = dataPreprocessor(rating_df, num_users, num_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pd6hxRtvzP0Y"
   },
   "outputs": [],
   "source": [
    "temp_matrix = np.zeros(q6df.shape)\n",
    "temp_matrix[q6df.nonzero()] = 1 \n",
    "userratingsnumber = np.sum(temp_matrix, axis=1)\n",
    "#userratingsnumber.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6A85yBIPzP2p"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(userratingsnumber, bins=50)\n",
    "plt.title(\"Histogram with 'auto' bins\")\n",
    "plt.show()\n",
    "#userratingsnumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sY_MAGUPzP5o"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "148.0"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(userratingsnumber,75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c109tvkczP8E"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "709"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresholdbelow = np.argwhere(userratingsnumber <= 148).flatten()\n",
    "len(thresholdbelow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "thDm5f32zP_Y"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "234"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresholdabove = np.argwhere(userratingsnumber > 148).flatten()\n",
    "len(thresholdabove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xQf_R-cazvSf"
   },
   "outputs": [],
   "source": [
    "class CrossValidationq6above(object):\n",
    "    def __init__(self, metric, data_path=path):\n",
    "        \"\"\"\n",
    "            INPUT:\n",
    "                metric: string. from['RMSE','P@K','R@K']\n",
    "        \"\"\"\n",
    "        self.folds = self._getData(path)\n",
    "        self.metric_name = metric\n",
    "        self.metric = self._getMetric(self.metric_name)\n",
    "        \n",
    "    def _getMetric(self, metric_name):\n",
    "        \"\"\"\n",
    "            Don't change this\n",
    "        \"\"\"\n",
    "        switcher = {\n",
    "            'RMSE': self.rmse,\n",
    "            'P@K': self.patk,\n",
    "            'R@K': self.ratk,\n",
    "        }\n",
    "        \n",
    "        return switcher[metric_name]\n",
    "    \n",
    "    @staticmethod\n",
    "    def rmse(data, k, num_users, num_items, pred, true='rating'):\n",
    "        \"\"\"\n",
    "            data: pandas DataFrame. \n",
    "            pred: string. Column name that corresponding to the prediction\n",
    "            true: string. Column name that corresponding to the true rating\n",
    "        \"\"\"\n",
    "        return sqrt(mean_squared_error(data[pred], data[true]))\n",
    "    \n",
    "    # Precision at k\n",
    "    def patk(self, data, k, num_users, num_items, pred, true='rating'):\n",
    "        \"\"\"\n",
    "            data: pandas DataFrame. \n",
    "            k: top-k items retrived\n",
    "            pred: string. Column name that corresponding to the prediction\n",
    "            true: string. Column name that corresponding to the true rating\n",
    "        \"\"\"\n",
    "        prediction = self.getMatrix(data, num_users, num_items, pred)\n",
    "        testSet =  self.getMatrix(data, num_users, num_items, true)\n",
    "    \n",
    "        # Initialize sum and count vars for average calculation\n",
    "        sumPrecisions = 0\n",
    "        countPrecisions = 0\n",
    "\n",
    "        # Define function for converting 1-5 rating to 0/1 (like / don't like)\n",
    "        vf = np.vectorize(lambda x: 1 if x >= 4 else 0)\n",
    "\n",
    "        for userID in range(num_users):\n",
    "            # Pick top K based on predicted rating\n",
    "            userVector = prediction[userID,:]\n",
    "            topK = nlargest(k, range(len(userVector)), userVector.take)\n",
    "\n",
    "            # Convert test set ratings to like / don't like\n",
    "            userTestVector = vf(testSet[userID,:]).nonzero()[0]\n",
    "\n",
    "            # Calculate precision\n",
    "            precision = float(len([item for item in topK if item in userTestVector]))/len(topK)\n",
    "\n",
    "            # Update sum and count\n",
    "            sumPrecisions += precision\n",
    "            countPrecisions += 1\n",
    "\n",
    "        # Return average P@k\n",
    "        return float(sumPrecisions)/countPrecisions\n",
    "    \n",
    "    # Recall at k\n",
    "    def ratk(self, data, k, num_users, num_items, pred, true='rating'):\n",
    "        \"\"\"\n",
    "            data: pandas DataFrame. \n",
    "            k: top-k items relevant\n",
    "            pred: string. Column name that corresponding to the prediction\n",
    "            true: string. Column name that corresponding to the true rating\n",
    "        \"\"\"\n",
    "        prediction = self.getMatrix(data, num_users, num_items, pred)\n",
    "        testSet =  self.getMatrix(data, num_users, num_items, true)\n",
    "        # Initialize sum and count vars for average calculation\n",
    "        sumRecalls = 0\n",
    "        countRecalls = 0\n",
    "\n",
    "        # Define function for converting 1-5 rating to 0/1 (like / don't like)\n",
    "        vf = np.vectorize(lambda x: 1 if x >= 4 else 0)\n",
    "\n",
    "        for userID in range(num_users):\n",
    "            # Pick top K based on predicted rating\n",
    "            userVector = prediction[userID,:]\n",
    "            topK = nlargest(k, range(len(userVector)), userVector.take)\n",
    "\n",
    "            # Convert test set ratings to like / don't like\n",
    "            userTestVector = vf(testSet[userID,:]).nonzero()[0]\n",
    "\n",
    "            # Ignore user if has no ratings in the test set\n",
    "            if (len(userTestVector) == 0):\n",
    "                continue\n",
    "\n",
    "            # Calculate recall\n",
    "            recall = float(len([item for item in topK if item in userTestVector]))/len(userTestVector)\n",
    "\n",
    "            # Update sum and count\n",
    "            sumRecalls += recall\n",
    "            countRecalls += 1\n",
    "\n",
    "        # Return average R@k\n",
    "        return float(sumRecalls)/countRecalls\n",
    "    \n",
    "    @staticmethod\n",
    "    def getMatrix(rating_df, num_users, num_items, column_name):\n",
    "        matrix = np.zeros((num_users, num_items))\n",
    "    \n",
    "        for (index, userID, itemID, value) in rating_df[['userID','itemID', column_name]].itertuples():\n",
    "            matrix[userID-1, itemID-1] = value\n",
    "            \n",
    "        return matrix\n",
    "    \n",
    "    @staticmethod\n",
    "    def _getData(data_path):\n",
    "        \"\"\"\n",
    "            Don't change this function\n",
    "        \"\"\"\n",
    "        folds = []\n",
    "        data_types = ['u{0}.base','u{0}.test']\n",
    "        for i in range(1,6):\n",
    "            train_set = getData(data_path, data_types[0].format(i))\n",
    "            train_set = train_set.loc[train_set['userID'].isin(thresholdabove)]\n",
    "            \n",
    "            test_set = getData(data_path, data_types[1].format(i))\n",
    "            test_set = test_set.loc[test_set['userID'].isin(thresholdabove)]\n",
    "            \n",
    "            folds.append([train_set, test_set])\n",
    "        return folds\n",
    "    \n",
    "    def run(self, algorithms, num_users, num_items, k=1):\n",
    "        \"\"\"\n",
    "            5-fold cross-validation\n",
    "            algorithms: list. a list of algorithms. \n",
    "                        eg: [user_cosine_recsys, item_euclidean_recsys]\n",
    "        \"\"\"\n",
    "        \n",
    "        scores = {}\n",
    "        for algorithm in algorithms:\n",
    "            print('Processing algorithm {0}'.format(algorithm.getPredColName()))\n",
    "            fold_scores = []\n",
    "            for fold in self.folds:\n",
    "                algorithm.reset()\n",
    "                algorithm.predict_all(fold[0], num_users, num_items)\n",
    "                prediction = algorithm.evaluate_test(fold[1])\n",
    "                pred_col = algorithm.getPredColName()\n",
    "                fold_scores.append(self.metric(prediction, k, num_users, num_items, pred_col))\n",
    "                \n",
    "            mean = np.mean(fold_scores)\n",
    "            ci_low, ci_high = stats.t.interval(0.95, len(fold_scores)-1, loc=mean, scale=stats.sem(fold_scores))\n",
    "            scores[algorithm.getPredColName()] = [fold_scores, mean, ci_low, ci_high]\n",
    "            \n",
    "        results = scores    \n",
    "    \n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8gMBqwk_zvVL"
   },
   "outputs": [],
   "source": [
    "item_cosine_recsys = SimBasedRecSys('item','cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0tgVRxclzvX1"
   },
   "outputs": [],
   "source": [
    "user_cosine_recsys = SimBasedRecSys('user','cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BeMbYA0Zzval"
   },
   "outputs": [],
   "source": [
    "# 1. gather your algorithms in previous steps.\n",
    "algorithm_instances_Q6 = [user_cosine_recsys,\n",
    "                          item_cosine_recsys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DqdNKuETzvfD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing algorithm user-cosine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5690it [00:01, 3613.85it/s]\n",
      "5970it [00:01, 3570.11it/s]\n",
      "5067it [00:01, 3649.60it/s]\n",
      "4833it [00:01, 3637.40it/s]\n",
      "4869it [00:01, 3618.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing algorithm item-cosine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5690it [00:01, 3218.61it/s]\n",
      "5970it [00:01, 3673.40it/s]\n",
      "5067it [00:01, 3607.05it/s]\n",
      "4833it [00:01, 3601.00it/s]\n",
      "4869it [00:01, 3575.23it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'user-cosine': [[1.0503720301028903,\n",
       "   1.0760128059562617,\n",
       "   1.0570055555699578,\n",
       "   1.054340869987063,\n",
       "   1.0468077895648276],\n",
       "  1.0569078102362,\n",
       "  1.042800757991966,\n",
       "  1.0710148624804339],\n",
       " 'item-cosine': [[1.0568322167581496,\n",
       "   1.058552860154752,\n",
       "   1.0251820359216575,\n",
       "   1.0437442042286282,\n",
       "   1.0722515432038346],\n",
       "  1.0513125720534044,\n",
       "  1.029262861402853,\n",
       "  1.073362282703956]}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_patk = CrossValidationq6above('RMSE')\n",
    "cv_patk.run(algorithm_instances_Q6, num_users, num_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XdTY1zLkzviQ"
   },
   "outputs": [],
   "source": [
    "class CrossValidationq6below(object):\n",
    "    def __init__(self, metric, data_path=path):\n",
    "        \"\"\"\n",
    "            INPUT:\n",
    "                metric: string. from['RMSE','P@K','R@K']\n",
    "        \"\"\"\n",
    "        self.folds = self._getData(path)\n",
    "        self.metric_name = metric\n",
    "        self.metric = self._getMetric(self.metric_name)\n",
    "        \n",
    "    def _getMetric(self, metric_name):\n",
    "        \"\"\"\n",
    "            Don't change this\n",
    "        \"\"\"\n",
    "        switcher = {\n",
    "            'RMSE': self.rmse,\n",
    "            'P@K': self.patk,\n",
    "            'R@K': self.ratk,\n",
    "        }\n",
    "        \n",
    "        return switcher[metric_name]\n",
    "    \n",
    "    @staticmethod\n",
    "    def rmse(data, k, num_users, num_items, pred, true='rating'):\n",
    "        \"\"\"\n",
    "            data: pandas DataFrame. \n",
    "            pred: string. Column name that corresponding to the prediction\n",
    "            true: string. Column name that corresponding to the true rating\n",
    "        \"\"\"\n",
    "        return sqrt(mean_squared_error(data[pred], data[true]))\n",
    "    \n",
    "    # Precision at k\n",
    "    def patk(self, data, k, num_users, num_items, pred, true='rating'):\n",
    "        \"\"\"\n",
    "            data: pandas DataFrame. \n",
    "            k: top-k items retrived\n",
    "            pred: string. Column name that corresponding to the prediction\n",
    "            true: string. Column name that corresponding to the true rating\n",
    "        \"\"\"\n",
    "        prediction = self.getMatrix(data, num_users, num_items, pred)\n",
    "        testSet =  self.getMatrix(data, num_users, num_items, true)\n",
    "    \n",
    "        # Initialize sum and count vars for average calculation\n",
    "        sumPrecisions = 0\n",
    "        countPrecisions = 0\n",
    "\n",
    "        # Define function for converting 1-5 rating to 0/1 (like / don't like)\n",
    "        vf = np.vectorize(lambda x: 1 if x >= 4 else 0)\n",
    "\n",
    "        for userID in range(num_users):\n",
    "            # Pick top K based on predicted rating\n",
    "            userVector = prediction[userID,:]\n",
    "            topK = nlargest(k, range(len(userVector)), userVector.take)\n",
    "\n",
    "            # Convert test set ratings to like / don't like\n",
    "            userTestVector = vf(testSet[userID,:]).nonzero()[0]\n",
    "\n",
    "            # Calculate precision\n",
    "            precision = float(len([item for item in topK if item in userTestVector]))/len(topK)\n",
    "\n",
    "            # Update sum and count\n",
    "            sumPrecisions += precision\n",
    "            countPrecisions += 1\n",
    "\n",
    "        # Return average P@k\n",
    "        return float(sumPrecisions)/countPrecisions\n",
    "    \n",
    "    # Recall at k\n",
    "    def ratk(self, data, k, num_users, num_items, pred, true='rating'):\n",
    "        \"\"\"\n",
    "            data: pandas DataFrame. \n",
    "            k: top-k items relevant\n",
    "            pred: string. Column name that corresponding to the prediction\n",
    "            true: string. Column name that corresponding to the true rating\n",
    "        \"\"\"\n",
    "        prediction = self.getMatrix(data, num_users, num_items, pred)\n",
    "        testSet =  self.getMatrix(data, num_users, num_items, true)\n",
    "        # Initialize sum and count vars for average calculation\n",
    "        sumRecalls = 0\n",
    "        countRecalls = 0\n",
    "\n",
    "        # Define function for converting 1-5 rating to 0/1 (like / don't like)\n",
    "        vf = np.vectorize(lambda x: 1 if x >= 4 else 0)\n",
    "\n",
    "        for userID in range(num_users):\n",
    "            # Pick top K based on predicted rating\n",
    "            userVector = prediction[userID,:]\n",
    "            topK = nlargest(k, range(len(userVector)), userVector.take)\n",
    "\n",
    "            # Convert test set ratings to like / don't like\n",
    "            userTestVector = vf(testSet[userID,:]).nonzero()[0]\n",
    "\n",
    "            # Ignore user if has no ratings in the test set\n",
    "            if (len(userTestVector) == 0):\n",
    "                continue\n",
    "\n",
    "            # Calculate recall\n",
    "            recall = float(len([item for item in topK if item in userTestVector]))/len(userTestVector)\n",
    "\n",
    "            # Update sum and count\n",
    "            sumRecalls += recall\n",
    "            countRecalls += 1\n",
    "\n",
    "        # Return average R@k\n",
    "        return float(sumRecalls)/countRecalls\n",
    "    \n",
    "    @staticmethod\n",
    "    def getMatrix(rating_df, num_users, num_items, column_name):\n",
    "        matrix = np.zeros((num_users, num_items))\n",
    "    \n",
    "        for (index, userID, itemID, value) in rating_df[['userID','itemID', column_name]].itertuples():\n",
    "            matrix[userID-1, itemID-1] = value\n",
    "            \n",
    "        return matrix\n",
    "    \n",
    "    @staticmethod\n",
    "    def _getData(data_path):\n",
    "        \"\"\"\n",
    "            Don't change this function\n",
    "        \"\"\"\n",
    "        folds = []\n",
    "        data_types = ['u{0}.base','u{0}.test']\n",
    "        for i in range(1,6):\n",
    "            train_set = getData(data_path, data_types[0].format(i))\n",
    "            train_set = train_set.loc[train_set['userID'].isin(thresholdbelow)]\n",
    "            \n",
    "            test_set = getData(data_path, data_types[1].format(i))\n",
    "            test_set = test_set.loc[test_set['userID'].isin(thresholdbelow)]\n",
    "            \n",
    "            folds.append([train_set, test_set])\n",
    "        return folds\n",
    "    \n",
    "    def run(self, algorithms, num_users, num_items, k=1):\n",
    "        \"\"\"\n",
    "            5-fold cross-validation\n",
    "            algorithms: list. a list of algorithms. \n",
    "                        eg: [user_cosine_recsys, item_euclidean_recsys]\n",
    "        \"\"\"\n",
    "        \n",
    "        scores = {}\n",
    "        for algorithm in algorithms:\n",
    "            print('Processing algorithm {0}'.format(algorithm.getPredColName()))\n",
    "            fold_scores = []\n",
    "            for fold in self.folds:\n",
    "                algorithm.reset()\n",
    "                algorithm.predict_all(fold[0], num_users, num_items)\n",
    "                prediction = algorithm.evaluate_test(fold[1])\n",
    "                pred_col = algorithm.getPredColName()\n",
    "                fold_scores.append(self.metric(prediction, k, num_users, num_items, pred_col))\n",
    "                \n",
    "            mean = np.mean(fold_scores)\n",
    "            ci_low, ci_high = stats.t.interval(0.95, len(fold_scores)-1, loc=mean, scale=stats.sem(fold_scores))\n",
    "            scores[algorithm.getPredColName()] = [fold_scores, mean, ci_low, ci_high]\n",
    "            \n",
    "        results = scores    \n",
    "    \n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eX0cQNy0zvlc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing algorithm user-cosine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14310it [00:04, 3550.91it/s]\n",
      "14030it [00:04, 3349.37it/s]\n",
      "14933it [00:04, 3521.63it/s]\n",
      "15120it [00:04, 3542.19it/s]\n",
      "15010it [00:04, 3544.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing algorithm item-cosine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14310it [00:04, 3316.21it/s]\n",
      "14030it [00:03, 3574.64it/s]\n",
      "14933it [00:04, 3551.18it/s]\n",
      "15120it [00:04, 3369.64it/s]\n",
      "15010it [00:04, 3542.58it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'user-cosine': [[1.0292964812509109,\n",
       "   1.0134988342423394,\n",
       "   1.0162441815962555,\n",
       "   1.0083129744573012,\n",
       "   1.0168529851897112],\n",
       "  1.0168410913473036,\n",
       "  1.0072353809052537,\n",
       "  1.0264468017893535],\n",
       " 'item-cosine': [[1.0462718991797464,\n",
       "   1.02116589621018,\n",
       "   1.0146139914163754,\n",
       "   1.016889536902209,\n",
       "   1.0147096245053064],\n",
       "  1.0227301896427634,\n",
       "  1.0060602497033544,\n",
       "  1.0394001295821724]}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_patk = CrossValidationq6below('RMSE')\n",
    "cv_patk.run(algorithm_instances_Q6, num_users, num_items,k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kk39wFyQ0IqQ"
   },
   "source": [
    "Q6) Analysis\n",
    "\n",
    "* For each metric the ave, low cI and high cI are considered.\n",
    "Below\n",
    "{'item-cosine': [ 1.022, 1.006, 1.039,\n",
    "'user-cosine': [ 1.016, 1.007, 1.026}\n",
    "Above\n",
    "{'item-cosine': [ 1.051, 1.029, 1.073,\n",
    "'user-cosine': [ 1.056, 1.042, 1.071]}\n",
    "Full members \n",
    "{'item-cosine': [ 1.020, 1.006, 1.033,\n",
    "'user-cosine': [ 1.017, 1.009, 1.025,\n",
    "\n",
    "* The RMSE values of below are less than Above. so the below perfomed better becuase in case for below we have more points (can see the number of iterations) and more vectors so better predictions. In the same way for full members as it has more information than either of the cases it performed slightly better.\n",
    "* But the above analysis cannot be generalized unless I see the other k values. Even I am changing the K values by 10 there is more diffence. There is tradeoof between number of vectors and number of ratings inside a vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation\n",
    "# Constants for validation only\n",
    "ROW_NUM = 943\n",
    "COL_NUM = 1682\n",
    "RATING_COL = 'rating'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7R8INqWu0Iv5"
   },
   "outputs": [],
   "source": [
    "def validateDataPreprocessor(path=path, getData=getData, getMatrix=CrossValidation.getMatrix):\n",
    "    validation_df = getData(path, 'u1.test')\n",
    "    try:\n",
    "        matrix = getMatrix(validation_df, ROW_NUM, COL_NUM, RATING_COL)\n",
    "    except:\n",
    "        print('dataPreprocessor function has error')\n",
    "        return\n",
    "    try:\n",
    "        assert(matrix.shape == (ROW_NUM,COL_NUM)),\\\n",
    "        \"Shape of matrix{0} doesn't match predefined shape (943,1682)\".format(matrix.shape)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    return validation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w8NiemQD0I1E"
   },
   "outputs": [],
   "source": [
    "validation_df = validateDataPreprocessor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PbYOo4bh0b5M"
   },
   "source": [
    "\n",
    "### Baseline Recommendation Systems\n",
    "\n",
    "#### Popularity Based Recommendation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MHpVXu_d0I3n"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    }
   ],
   "source": [
    "def validatePopularityRecSys(validation_df=validation_df, BaseLineRecSys = BaseLineRecSys):\n",
    "    popularity_recsys = BaseLineRecSys('popularity')\n",
    "    try:\n",
    "        popularity_recsys.predict_all(validation_df, ROW_NUM, COL_NUM)\n",
    "    except Exception as e:        \n",
    "        print('popularity function has error')\n",
    "        print(e)\n",
    "        return\n",
    "    try:\n",
    "        predictionMatrix = popularity_recsys.getModel()\n",
    "        assert(predictionMatrix.shape == (ROW_NUM, COL_NUM)),\\\n",
    "        \"Shape of matrix{0} doesn't match predefined shape ({1},{2})\"\\\n",
    "        .format(predictionMatrix.shape,ROW_NUM, COL_NUM)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "validatePopularityRecSys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yFA5rvbd0jN5"
   },
   "source": [
    "#### User Average Based Recommendation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dOUQserL0I8w"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    }
   ],
   "source": [
    "def validateUserAverRecSys(validation_df=validation_df, BaseLineRecSys = BaseLineRecSys):\n",
    "    useraverage_recsys = BaseLineRecSys('useraverage')\n",
    "    try:\n",
    "        useraverage_recsys.predict_all(validation_df, ROW_NUM, COL_NUM)\n",
    "    except:\n",
    "        print('useraverage function has error')\n",
    "        return\n",
    "    try:\n",
    "        predictionMatrix = useraverage_recsys.getModel()\n",
    "        assert(predictionMatrix.shape == (ROW_NUM, COL_NUM)),\\\n",
    "        \"Shape of matrix{0} doesn't match predefined shape ({1},{2})\"\\\n",
    "        .format(predictionMatrix.shape,ROW_NUM, COL_NUM)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "validateUserAverRecSys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LQE3qw-L0sWr"
   },
   "source": [
    "\n",
    "\n",
    "### Similary Based Recommendation Systems\n",
    "\n",
    "#### Euclidean Similarity Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o9Pmcdn50JAH"
   },
   "outputs": [],
   "source": [
    "def validateEuclidean(validation_df=validation_df, getMatrix=CrossValidation.getMatrix):\n",
    "    matrix = getMatrix(validation_df, ROW_NUM, COL_NUM, RATING_COL)\n",
    "    try:\n",
    "        sim_matrix = SimBasedRecSys.euclidean(matrix)\n",
    "        assert(sim_matrix.shape == (ROW_NUM, ROW_NUM)),\\\n",
    "        \"Shape of matrix{0} doesn't match predefined shape ({1},{2})\"\\\n",
    "        .format(sim_matrix.shape,ROW_NUM,ROW_NUM)\n",
    "        assert(np.any(sim_matrix <= 1)),\\\n",
    "               \"Exist similarity value that is not less or equal to 1.\"\n",
    "    except Exception as e:\n",
    "        print(e)        \n",
    "\n",
    "validateEuclidean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hQifVk1X1B32"
   },
   "source": [
    "#### Customized Similarity Function (test somethingelse function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3jQnlA2e0I6l"
   },
   "outputs": [],
   "source": [
    "def validateCustomizedSim(validation_df=validation_df, getMatrix=CrossValidation.getMatrix):\n",
    "    matrix = getMatrix(validation_df, ROW_NUM, COL_NUM, RATING_COL)\n",
    "    try:\n",
    "        sim_matrix = SimBasedRecSys.somethingelse(matrix)\n",
    "        assert(sim_matrix.shape == (ROW_NUM, ROW_NUM)),\\\n",
    "        \"Shape of matrix{0} doesn't match predefined shape ({1},{2})\"\\\n",
    "        .format(sim_matrix.shape,ROW_NUM,ROW_NUM)\n",
    "        assert(np.any(sim_matrix <= 1)),\\\n",
    "               \"Exist similarity value that is not less or equal to 1.\"\n",
    "    except Exception as e:\n",
    "        print(e) \n",
    "\n",
    "validateCustomizedSim()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iKMw_-tq0_Bq"
   },
   "source": [
    "#### User-User Similarity Based Recommendation System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ou1QKZou0Iy_"
   },
   "outputs": [],
   "source": [
    "def validateUUSimBasedRecSys(validation_df=validation_df, dataPreprocessor=dataPreprocessor):\n",
    "    try:\n",
    "        user_cosine_recsys = SimBasedRecSys('user','cosine', dataPreprocessor)\n",
    "    except:\n",
    "        print(\"Framework error, please make sure you are using given yml file.\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        user_cosine_recsys.predict_all(validation_df, ROW_NUM, COL_NUM)\n",
    "        predictionMatrix = user_cosine_recsys.getModel()\n",
    "        assert(predictionMatrix.shape == (ROW_NUM, COL_NUM)),\\\n",
    "        \"Shape of matrix{0} doesn't match predefined shape ({1},{2})\"\\\n",
    "        .format(predictionMatrix.shape,ROW_NUM, COL_NUM)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "validateUUSimBasedRecSys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LetKshXY07Y2"
   },
   "source": [
    "#### Item-Item Similarity Based Recommendation System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SL_vF9tBzvc9"
   },
   "outputs": [],
   "source": [
    "def validateIISimBasedRecSys(validation_df=validation_df, dataPreprocessor=dataPreprocessor):\n",
    "    try:\n",
    "        user_cosine_recsys = SimBasedRecSys('item','cosine', dataPreprocessor)\n",
    "    except:\n",
    "        print(\"Framework error, please make sure you are using given yml file.\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        user_cosine_recsys.predict_all(validation_df, ROW_NUM, COL_NUM)\n",
    "        predictionMatrix = user_cosine_recsys.getModel()\n",
    "        assert(predictionMatrix.shape == (ROW_NUM, COL_NUM)),\\\n",
    "        \"Shape of matrix{0} doesn't match predefined shape ({1},{2})\"\\\n",
    "        .format(predictionMatrix.shape,ROW_NUM, COL_NUM)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "validateIISimBasedRecSys()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Recommender Systems.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
