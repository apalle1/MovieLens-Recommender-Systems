{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Github-Recommender-System.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngjDneN98R8n"
      },
      "source": [
        "# Recommender system"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FigfpnWjeEnq",
        "outputId": "e7983eda-84c9-4f86-a028-c6ac9a27e0de"
      },
      "source": [
        "# Mount google drive\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive')\r\n",
        "%cd /content/gdrive/My Drive/Datasets/Movielens-100k"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n",
            "/content/gdrive/My Drive/Datasets/Movielens-100k\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltcsRQJ7o31N"
      },
      "source": [
        "# import required libraries\n",
        "import os\n",
        "import os.path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from math import sqrt\n",
        "from heapq import nlargest\n",
        "from tqdm import trange\n",
        "from tqdm import tqdm\n",
        "from scipy import stats\n",
        "from sklearn.metrics.pairwise import pairwise_distances\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "MOVIELENS_DIR = \"ml-100k\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftawuk5oexrr"
      },
      "source": [
        "# Load the dataset\r\n",
        "def getData(folder_path, file_name):\r\n",
        "    fields = ['userID', 'itemID', 'rating', 'timestamp']\r\n",
        "    data = pd.read_csv(os.path.join(folder_path, file_name), sep='\\t', names=fields)\r\n",
        "    return data \r\n",
        "\r\n",
        "rating_df = getData(MOVIELENS_DIR, 'u.data')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "3qZtCOMpe3b2",
        "outputId": "bd251dae-1d09-4804-e51e-36422d629c03"
      },
      "source": [
        "rating_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userID</th>\n",
              "      <th>itemID</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>196</td>\n",
              "      <td>242</td>\n",
              "      <td>3</td>\n",
              "      <td>881250949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>186</td>\n",
              "      <td>302</td>\n",
              "      <td>3</td>\n",
              "      <td>891717742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>22</td>\n",
              "      <td>377</td>\n",
              "      <td>1</td>\n",
              "      <td>878887116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>244</td>\n",
              "      <td>51</td>\n",
              "      <td>2</td>\n",
              "      <td>880606923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>166</td>\n",
              "      <td>346</td>\n",
              "      <td>1</td>\n",
              "      <td>886397596</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   userID  itemID  rating  timestamp\n",
              "0     196     242       3  881250949\n",
              "1     186     302       3  891717742\n",
              "2      22     377       1  878887116\n",
              "3     244      51       2  880606923\n",
              "4     166     346       1  886397596"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5o4j_38xoqQF",
        "outputId": "0d8a2ba5-377c-4851-cb79-2d2ad2dd79ae"
      },
      "source": [
        "num_users = len(rating_df.userID.unique())\n",
        "num_items = len(rating_df.itemID.unique())\n",
        "print(\"Number of users:\", num_users)\n",
        "print(\"Number of items:\", num_items)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of users: 943\n",
            "Number of items: 1682\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCzcixhscrqc"
      },
      "source": [
        "### Q1. Data Preprocessing and Baseline algorithms\r\n",
        "\r\n",
        "(a) Data in recommendation systems is usually encoded as data frame with three or more columns: (user, item, rating, additional meta-data if present). Complete the function **dataPreprocessor** that takes the data frame, total number of users, total number of items and it should output a **`user-item matrix`**. The following experiments will all use **dataPreprocessor**.\r\n",
        "\r\n",
        "(b) In this question, we'll port the baseline algorithms from the lab to our evaluation framework for the assignment. To do so, you need to implement the two baseline algorithms (popularity, user average rating). Please fill in the indicated functions (**popularity**, **useraverage**) in class **BaseLineRecSys**; see comments there for more guidance. The rest of **BaseLineRecSys** has been written for you."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eB3BnXJaoqSZ"
      },
      "source": [
        "# Q1-(a)\n",
        "# https://stackoverflow.com/questions/16476924/how-to-iterate-over-rows-in-a-dataframe-in-pandas\n",
        "# https://stackoverflow.com/questions/34962104/pandas-how-can-i-use-the-apply-function-for-a-single-column\n",
        "def dataPreprocessor(rating_df, num_users, num_items):\n",
        "    \"\"\"\n",
        "    INPUT: \n",
        "        data: pandas DataFrame. columns=['userID', 'itemID', 'rating' ...]\n",
        "        num_row: int. number of users\n",
        "        num_col: int. number of items\n",
        "    OUTPUT:\n",
        "        matrix: 2D numpy array. \n",
        "        \n",
        "    NOTE 1: see where something very similar is done in the lab in function 'buildUserItemMatrix'    \n",
        "        \n",
        "    NOTE 2: data can have more columns, but your function should ignore \n",
        "          additional columns.\n",
        "    \"\"\"\n",
        "    ########### your code goes here ###########\n",
        "    # Initialize a of size (numUsers, numItems) to zeros\n",
        "    matrix = np.zeros((num_users, num_items), dtype=np.int8)\n",
        "    \n",
        "    # Populate the matrix based on the dataset\n",
        "    for (index, userID, itemID, rating, timestamp) in rating_df.itertuples():\n",
        "        matrix[userID-1, itemID-1] = rating\n",
        "    ###########         end         ###########\n",
        "    return matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8h69CaroqVx",
        "outputId": "c9b10314-4e3a-48a8-c35f-07d8fbd139eb"
      },
      "source": [
        "dataPreprocessor(rating_df, num_users, num_items)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5, 3, 4, ..., 0, 0, 0],\n",
              "       [4, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [5, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 5, 0, ..., 0, 0, 0]], dtype=int8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WK9unZg5rs66"
      },
      "source": [
        "# Q1-(b)\n",
        "# https://numpy.org/devdocs/reference/generated/numpy.ndenumerate.html\n",
        "# https://numpy.org/doc/stable/reference/generated/numpy.nonzero.html\n",
        "class BaseLineRecSys(object):\n",
        "    def __init__(self, method, processor=dataPreprocessor):\n",
        "        \"\"\"\n",
        "        method: string. From ['popularity','useraverage']\n",
        "        processor: function name. dataPreprocessor by default\n",
        "        \"\"\"\n",
        "        self.method_name = method\n",
        "        self.method = self._getMethod(self.method_name)\n",
        "        self.processor = processor\n",
        "        self.pred_column_name = self.method_name\n",
        "\n",
        "    def _getMethod(self, method_name):\n",
        "        \"\"\"\n",
        "        Don't change this\n",
        "        \"\"\"\n",
        "        switcher = {\n",
        "            'popularity': self.popularity,\n",
        "            'useraverage': self.useraverage,\n",
        "        }\n",
        "        \n",
        "        return switcher[method_name]\n",
        "\n",
        "    @staticmethod\n",
        "    def useraverage(train_matrix, num_users, num_items):\n",
        "        \"\"\"\n",
        "        INPUT:\n",
        "            train_matrix: 2D numpy array.\n",
        "            num_users: int. Number of Users.\n",
        "            num_items: int. Number of Items.\n",
        "        OUTPUT:\n",
        "            predictionMatrix: 2D numpy array. this is the same dimensions and \n",
        "            row/column IDs as train_matrix, but anywhere there is a 0 in train_matrix, \n",
        "            there should be a predicted value in predictedMatrix.\n",
        "            \n",
        "        NOTE: see where something very similar is done in the lab in function 'predictByUserAverage'    \n",
        "        \"\"\"\n",
        "        predictionMatrix = np.zeros((num_users, num_items))\n",
        "        ########### your code goes here ###########\n",
        "        for (user, item), rating in np.ndenumerate(train_matrix):\n",
        "        # Predict rating for every item that wasn't ranked by the user (rating == 0)\n",
        "            # Extract the items the user already rated\n",
        "            userVector = train_matrix[user, :]\n",
        "            ratedItems = userVector[userVector.nonzero()]\n",
        "\n",
        "            # If not empty, calculate average and set as rating for the current item\n",
        "            if ratedItems.size == 0:\n",
        "                itemAvg = 0\n",
        "            else:\n",
        "                itemAvg = ratedItems.mean()\n",
        "            predictionMatrix[user, item] = itemAvg\n",
        "\n",
        "            # report progress every 100 users\n",
        "            if (user % 100 == 0 and item == 1):\n",
        "                print (\"calculated %d users\" % (user,))\n",
        "        ###########         end         ###########\n",
        "        return predictionMatrix\n",
        "    \n",
        "    @staticmethod\n",
        "    def popularity(train_matrix, num_users, num_items):\n",
        "        \"\"\"\n",
        "        INPUT:\n",
        "            train_matrix: 2D numpy array.\n",
        "            num_users: int. Number of Users.\n",
        "            num_items: int. Number of Items.\n",
        "        OUTPUT:\n",
        "            predictionMatrix: 2D numpy array. this is the same dimensions and \n",
        "            row/column IDs as train_matrix, but anywhere there is a 0 in train_matrix, \n",
        "            there should be a predicted value in predictedMatrix.\n",
        "            \n",
        "        NOTE: see where something very similar is done in the lab in function 'predictByPopularity'    \n",
        "        \"\"\"\n",
        "        predictionMatrix = np.zeros((num_users, num_items))\n",
        "        ########### your code goes here ###########\n",
        "        # Define function for converting 1-5 rating to 0/1 (like / don't like)\n",
        "        vf = np.vectorize(lambda x: 1 if x >= 4 else 0)\n",
        "\n",
        "        # For every item calculate the number of people liked (4-5) divided by the number of people that rated\n",
        "        itemPopularity = np.zeros((num_items))\n",
        "        for item in range(num_items):\n",
        "            numOfUsersRated = len(train_matrix[:, item].nonzero()[0])\n",
        "            numOfUsersLiked = len(vf(train_matrix[:, item]).nonzero()[0])\n",
        "            if numOfUsersRated == 0:\n",
        "                itemPopularity[item] = 0\n",
        "            else:\n",
        "                itemPopularity[item] = numOfUsersLiked/numOfUsersRated\n",
        "\n",
        "        for (user, item), rating in np.ndenumerate(train_matrix):\n",
        "            # Predict rating for every item that wasn't ranked by the user (rating == 0)\n",
        "            predictionMatrix[user, item] = itemPopularity[item]\n",
        "\n",
        "            # report progress every 100 users\n",
        "            if (user % 100 == 0 and item == 1):\n",
        "                print (\"calculated %d users\" % (user,))\n",
        "        ###########         end         ###########\n",
        "        return predictionMatrix    \n",
        "    \n",
        "    def predict_all(self, train_df, num_users, num_items):\n",
        "        \n",
        "        train_matrix = self.processor(train_df, num_users, num_items)\n",
        "        self.__model = self.method(train_matrix, num_users, num_items)\n",
        "        \n",
        "    def evaluate_test(self, test_df, copy=False):\n",
        "        \n",
        "        if copy:\n",
        "            prediction = test_df.copy()\n",
        "        else:\n",
        "            prediction = test_df\n",
        "            \n",
        "        prediction[self.pred_column_name] = np.nan\n",
        "        \n",
        "        for (index, \n",
        "             userID, \n",
        "             itemID) in tqdm(prediction[['userID','itemID']].itertuples()):\n",
        "            prediction.loc[index, self.pred_column_name] = self.__model[userID-1, itemID-1]\n",
        "\n",
        "        return prediction\n",
        "        \n",
        "    def getModel(self):\n",
        "        \"\"\"\n",
        "        return predicted user-item matrix\n",
        "        \"\"\"\n",
        "        return self.__model\n",
        "    \n",
        "    def getPredColName(self):\n",
        "        \"\"\"\n",
        "        return prediction column name\n",
        "        \"\"\"\n",
        "        return self.pred_column_name\n",
        "    \n",
        "    def reset(self):\n",
        "        \"\"\"\n",
        "        reuse the instance of the class by removing model\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.model = None\n",
        "        except:\n",
        "            print(\"You don not have model..\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tb8Hc-TTsjOE",
        "outputId": "ff5f7963-a79b-487f-8ca7-bc15b78f0718"
      },
      "source": [
        "average_user_rating_recsys = BaseLineRecSys('useraverage')\r\n",
        "average_user_rating_recsys.predict_all(rating_df, num_users, num_items)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yiN0YJOTsjI2",
        "outputId": "65eb4cff-2cc6-45cf-f360-9b2ad7c3b684"
      },
      "source": [
        "average_user_rating_recsys.getModel()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3.61029412, 3.61029412, 3.61029412, ..., 3.61029412, 3.61029412,\n",
              "        3.61029412],\n",
              "       [3.70967742, 3.70967742, 3.70967742, ..., 3.70967742, 3.70967742,\n",
              "        3.70967742],\n",
              "       [2.7962963 , 2.7962963 , 2.7962963 , ..., 2.7962963 , 2.7962963 ,\n",
              "        2.7962963 ],\n",
              "       ...,\n",
              "       [4.04545455, 4.04545455, 4.04545455, ..., 4.04545455, 4.04545455,\n",
              "        4.04545455],\n",
              "       [4.26582278, 4.26582278, 4.26582278, ..., 4.26582278, 4.26582278,\n",
              "        4.26582278],\n",
              "       [3.41071429, 3.41071429, 3.41071429, ..., 3.41071429, 3.41071429,\n",
              "        3.41071429]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "PbBpl-ZPsjGV",
        "outputId": "915c1f4a-1b4f-4f10-9241-a6f32ee9aa78"
      },
      "source": [
        "average_user_rating_recsys.evaluate_test(rating_df, copy=True).head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100000it [01:17, 1296.19it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userID</th>\n",
              "      <th>itemID</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>useraverage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>196</td>\n",
              "      <td>242</td>\n",
              "      <td>3</td>\n",
              "      <td>881250949</td>\n",
              "      <td>3.615385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>186</td>\n",
              "      <td>302</td>\n",
              "      <td>3</td>\n",
              "      <td>891717742</td>\n",
              "      <td>3.413043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>22</td>\n",
              "      <td>377</td>\n",
              "      <td>1</td>\n",
              "      <td>878887116</td>\n",
              "      <td>3.351562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>244</td>\n",
              "      <td>51</td>\n",
              "      <td>2</td>\n",
              "      <td>880606923</td>\n",
              "      <td>3.651261</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>166</td>\n",
              "      <td>346</td>\n",
              "      <td>1</td>\n",
              "      <td>886397596</td>\n",
              "      <td>3.550000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   userID  itemID  rating  timestamp  useraverage\n",
              "0     196     242       3  881250949     3.615385\n",
              "1     186     302       3  891717742     3.413043\n",
              "2      22     377       1  878887116     3.351562\n",
              "3     244      51       2  880606923     3.651261\n",
              "4     166     346       1  886397596     3.550000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnkG4TL8r9lz",
        "outputId": "cfbc08ec-54fd-4c62-e5c0-292cc8933272"
      },
      "source": [
        "popularity_recsys = BaseLineRecSys('popularity')\r\n",
        "popularity_recsys.predict_all(rating_df, num_users, num_items)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVqYNSscsDHO",
        "outputId": "29f6c092-8acb-496c-d576-ac203680725c"
      },
      "source": [
        "popularity_recsys.getModel()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.71017699, 0.38931298, 0.37777778, ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.71017699, 0.38931298, 0.37777778, ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.71017699, 0.38931298, 0.37777778, ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       ...,\n",
              "       [0.71017699, 0.38931298, 0.37777778, ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.71017699, 0.38931298, 0.37777778, ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.71017699, 0.38931298, 0.37777778, ..., 0.        , 0.        ,\n",
              "        0.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "ZvTkeF9KsDMF",
        "outputId": "f0b6eb51-93d1-488a-8271-754db40ab77d"
      },
      "source": [
        "popularity_recsys.evaluate_test(rating_df, copy=True).head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100000it [01:15, 1330.54it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userID</th>\n",
              "      <th>itemID</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>popularity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>196</td>\n",
              "      <td>242</td>\n",
              "      <td>3</td>\n",
              "      <td>881250949</td>\n",
              "      <td>0.760684</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>186</td>\n",
              "      <td>302</td>\n",
              "      <td>3</td>\n",
              "      <td>891717742</td>\n",
              "      <td>0.804714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>22</td>\n",
              "      <td>377</td>\n",
              "      <td>1</td>\n",
              "      <td>878887116</td>\n",
              "      <td>0.076923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>244</td>\n",
              "      <td>51</td>\n",
              "      <td>2</td>\n",
              "      <td>880606923</td>\n",
              "      <td>0.555556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>166</td>\n",
              "      <td>346</td>\n",
              "      <td>1</td>\n",
              "      <td>886397596</td>\n",
              "      <td>0.611111</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   userID  itemID  rating  timestamp  popularity\n",
              "0     196     242       3  881250949    0.760684\n",
              "1     186     302       3  891717742    0.804714\n",
              "2      22     377       1  878887116    0.076923\n",
              "3     244      51       2  880606923    0.555556\n",
              "4     166     346       1  886397596    0.611111"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFkpSK8kcrqh"
      },
      "source": [
        "### Q2. Similarity in Collaborative Filtering\r\n",
        "(a) In class **SimBasedRecSys**, there are two similarity measurement functions (**cosine**, **euclidean**). Please fill in the missing part of those functions. Be careful how you convert Euclidean distance to a [0, 1] similarity for use in the recommender. This implementation is very short and should use pairwise distance. (Google for \"pairwise distance scikit learn\" for a list of distance metrics, more Googling will tell you what they mean.) Which metric works better? Why?\r\n",
        "\r\n",
        "(b) Implement an additional third metric in function **somethingelse** (your choice, see other offerings of pairwise_distance) and justify in a sentence why you think this could be a good similarity metric for user or item comparison in collaborative filtering."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0csD4wMsjDs"
      },
      "source": [
        "class SimBasedRecSys(object):\n",
        "\n",
        "    def __init__(self, base, method, processor=dataPreprocessor):\n",
        "        \"\"\"\n",
        "        base: string. From ['user', 'item']. User-based Similarity or Item-based\n",
        "        method: string. From ['cosine', 'euclidean', 'somethingelse']\n",
        "        processor: function name. dataPreprocessor by default\n",
        "        \"\"\"\n",
        "        self.base = base\n",
        "        self.method_name = method\n",
        "        self.method = self._getMethod(self.method_name)\n",
        "        self.processor = processor\n",
        "        self.pred_column_name = self.base+'-'+self.method_name\n",
        "    \n",
        "    def _getMethod(self, method_name):\n",
        "        \"\"\"\n",
        "        Don't change this\n",
        "        \"\"\"\n",
        "        switcher = {\n",
        "            'cosine': self.cosine,\n",
        "            'euclidean': self.euclidean,\n",
        "            'somethingelse': self.somethingelse,\n",
        "        }\n",
        "        \n",
        "        return switcher[method_name]\n",
        "    \n",
        "    @staticmethod\n",
        "    def cosine(matrix):\n",
        "        \"\"\"\n",
        "        cosine similarity\n",
        "        \"\"\"\n",
        "        ########### your code goes here ###########\n",
        "        similarity_matrix = 1 - pairwise_distances(matrix, metric='cosine')\n",
        "        ###########         end         ###########\n",
        "        return similarity_matrix\n",
        "    \n",
        "    @staticmethod\n",
        "    def euclidean(matrix):\n",
        "        \"\"\"\n",
        "        euclidean similarity\n",
        "        INPUT\n",
        "          rating matrix generated by dataPreprocessor with R rows and C columns. \n",
        "        OUTPUT \n",
        "          an R x R similarity_matrix S where each S_ij should be the euclidean similarity between row i and row j of the rating matrix.\n",
        "        \"\"\"\n",
        "        ########### your code goes here ###########\n",
        "        similarity_matrix = 1 /(1 + pairwise_distances(matrix, metric='euclidean'))\n",
        "        ###########         end         ###########\n",
        "        return similarity_matrix\n",
        "    \n",
        "    @staticmethod\n",
        "    def somethingelse(matrix):\n",
        "        \"\"\"\n",
        "        manhattan? or super-natural intuition similarity\n",
        "        \"\"\"\n",
        "        ########### your code goes here ###########\n",
        "        similarity_matrix = 1 /(1 + pairwise_distances(matrix, metric='manhattan'))\n",
        "        ###########         end         ###########        \n",
        "        return similarity_matrix\n",
        "        \n",
        "    def predict_all(self, train_df, num_users, num_items):\n",
        "        \"\"\"\n",
        "        INPUT: \n",
        "            data: pandas DataFrame. columns=['userID', 'itemID', 'rating'...]\n",
        "            num_row: scalar. number of users\n",
        "            num_col: scalar. number of items\n",
        "        OUTPUT:\n",
        "            no return... this method assigns the result to self.model\n",
        "        \n",
        "        NOTES:\n",
        "            self.__model should contain predictions for *all* user and items\n",
        "            (don't worry about predicting for observed (user,item) pairs,\n",
        "              since we won't be using these predictions in the evaluation)\n",
        "            (see code in for an efficient vectorized example)\n",
        "        \"\"\"\n",
        "        train_matrix = self.processor(train_df, num_users, num_items)\n",
        "        \n",
        "        if self.base == 'user':\n",
        "            ########### your code goes here ###########\n",
        "            temp_matrix = np.zeros(train_matrix.shape)\n",
        "            temp_matrix[train_matrix.nonzero()] = 1\n",
        "            uu_similarity = 1 - pairwise_distances(train_matrix, metric='cosine')\n",
        "            normalizer = np.matmul(uu_similarity, temp_matrix)\n",
        "            normalizer[normalizer == 0] = 1e-5\n",
        "            predictionMatrix = np.matmul(uu_similarity, train_matrix)/normalizer\n",
        "            useraverage = np.sum(train_matrix, axis=1)/np.sum(temp_matrix, axis=1)\n",
        "            columns = np.sum(predictionMatrix, axis=0)\n",
        "            predictionMatrix[:, columns==0] = predictionMatrix[:, columns==0] + np.expand_dims(useraverage, axis=1)\n",
        "            self.__model = predictionMatrix\n",
        "            ###########         end         ###########\n",
        "            \n",
        "        elif self.base == 'item':\n",
        "            ########### your code goes here ###########\n",
        "            temp_matrix = np.zeros(train_matrix.shape)\n",
        "            temp_matrix[train_matrix.nonzero()] = 1\n",
        "            ii_similarity = 1 - pairwise_distances(train_matrix.T, metric='cosine')\n",
        "            normalizer = np.matmul(temp_matrix, ii_similarity)\n",
        "            normalizer[normalizer == 0] = 1e-5\n",
        "            tt_model = np.matmul(train_matrix, ii_similarity)/normalizer\n",
        "            useraverage = np.sum(train_matrix, axis=1)/np.sum(temp_matrix, axis=1)\n",
        "            columns = np.sum(tt_model, axis=0)\n",
        "            tt_model[:, columns==0] = tt_model[:, columns==0] + np.expand_dims(useraverage, axis=1)\n",
        "            self.__model = tt_model\n",
        "            ###########         end         ###########\n",
        "        else:\n",
        "            print('No other option available')\n",
        "        \n",
        "    def evaluate_test(self, test_df, copy=False):\n",
        "        \"\"\"\n",
        "        INPUT:\n",
        "            data: pandas DataFrame. columns=['userID', 'itemID', 'rating'...]\n",
        "        OUTPUT:\n",
        "            predictions:  pandas DataFrame. \n",
        "                          columns=['userID', 'itemID', 'rating', 'base-method'...]\n",
        "                          \n",
        "        NOTE: 1. data can have more columns, but your function should ignore \n",
        "              additional columns.\n",
        "              2. 'base-method' depends on your 'base' and 'method'. For example,\n",
        "              if base == 'user' and method == 'cosine', \n",
        "              then base-method == 'user-cosine'\n",
        "              3. your predictions go to 'base-method' column\n",
        "        \"\"\"\n",
        "        if copy:\n",
        "            prediction = test_df.copy()\n",
        "        else:\n",
        "            prediction = test_df\n",
        "        prediction[self.pred_column_name] = np.nan\n",
        "        \n",
        "        for (index, \n",
        "             userID, \n",
        "             itemID) in tqdm(prediction[['userID','itemID']].itertuples()):\n",
        "            prediction.loc[index, self.pred_column_name] = self.__model[userID-1, itemID-1]\n",
        "    \n",
        "        return prediction\n",
        "    \n",
        "    def getModel(self):\n",
        "        \"\"\"\n",
        "        return predicted user-item matrix\n",
        "        \"\"\"\n",
        "        return self.__model\n",
        "    \n",
        "    def getPredColName(self):\n",
        "        \"\"\"\n",
        "        return prediction column name\n",
        "        \"\"\"\n",
        "        return self.pred_column_name\n",
        "    \n",
        "    def reset(self):\n",
        "        \"\"\"\n",
        "        reuse the instance of the class by removing model\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.model = None\n",
        "        except:\n",
        "            print(\"You do not have model..\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjM_qhTvcrql",
        "outputId": "c271ef7b-ccc7-4dc9-e070-545e01e555f7"
      },
      "source": [
        "# Examples of how to call similarity functions.\n",
        "I = np.eye(3)\n",
        "SimBasedRecSys.cosine(I)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CurBMqdcrqn",
        "outputId": "fd619cb8-2606-4ac1-f564-19ab04a9ae96"
      },
      "source": [
        "SimBasedRecSys.euclidean(I)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.        , 0.41421356, 0.41421356],\n",
              "       [0.41421356, 1.        , 0.41421356],\n",
              "       [0.41421356, 0.41421356, 1.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbNftg3Vcrqo",
        "outputId": "5820d753-3c21-4367-fbd0-fc5b31e9efaa"
      },
      "source": [
        "SimBasedRecSys.somethingelse(I)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.        , 0.33333333, 0.33333333],\n",
              "       [0.33333333, 1.        , 0.33333333],\n",
              "       [0.33333333, 0.33333333, 1.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7EYa1Hx1crqo"
      },
      "source": [
        "Analysis: \n",
        "* Cosine works better than Euclidean mainly due to length normalization.\n",
        "* But in our case we also normalized values of Euclidean so both are having overlap in confidence intervals for RMSE.\n",
        "* For example If I have two users who rated (4,4) and (5,5) two movies they can still be similar because each user has different relative perspectives both of them didnt hate the movie. So in this case cosine works better than Euclidean.\n",
        "* For example If I have two user who rated (1,1) and (5,5) two movies. Cosine says they are similar but clearly they are not.\n",
        "* From our results in Q4\n",
        "\n",
        "```\n",
        "'user-euclidean': [[1.0319953645887305, 1.013706565892023, 1.031268958300787],\n",
        "'item-euclidean': [[1.0452460304884215, 1.0157114777932958, 1.0413212192481176,\n",
        "'user-cosine': [[1.026449013124381, 1.009013080226148, 1.0256951630950135], \n",
        "'item-cosine': [[1.0377631264364244, 1.0068242686250732, 1.0333415315874226]\n",
        "```\n",
        "\n",
        "* Manhattan is choosen because it calculates the distance of two vectors by absolute differences. It is similar to Euclidean because we are normalizing both of them (similar results checked in bottom). In case of manhattan it is more robust and it requires less calculations.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZC9EG4j8crqo"
      },
      "source": [
        "### Q3. Collaborative Filtering\r\n",
        "(a) Leveraging the user-user collaborative filtering example from lab, implement user-user and item-item based collaborative filtering algorithms by filling out the **predict_all** function in class **SimBasedRecSys**. Note that you should implement vectorized versions of collaborative filtering (example give in lab) since loop-based versions will take excessively long to run.\r\n",
        "\r\n",
        "(b) Please use the given class **CrossValidation** to report comparative **RMSE** results (averages and confidence intervals) between user-user and item-item based collaborative filtering for cosine similarity. Can you explain why one method may have performed better? Consider the average number of ratings per user and the average number of ratings per item when you state your answer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnKe5CDfsjBH"
      },
      "source": [
        "user_cosine_recsys = SimBasedRecSys('user', 'cosine')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fbfyE3FtXZK"
      },
      "source": [
        "item_cosine_recsys = SimBasedRecSys('item', 'cosine')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeIqY0J4tXbZ"
      },
      "source": [
        "user_cosine_recsys.predict_all(rating_df, num_users, num_items)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5mdbxj-tXd7",
        "outputId": "d37c8fc2-4b0d-4353-d427-10a3e2cf9a74"
      },
      "source": [
        "user_cosine_recsys.getModel()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3.89911175, 3.19022667, 3.0261129 , ..., 2.        , 3.        ,\n",
              "        3.        ],\n",
              "       [3.84034456, 3.17139889, 2.92626717, ..., 2.        , 3.        ,\n",
              "        3.        ],\n",
              "       [3.87104065, 3.12823798, 3.03250708, ..., 2.        , 3.        ,\n",
              "        3.        ],\n",
              "       ...,\n",
              "       [3.90754645, 3.20227238, 3.05776201, ..., 2.        , 3.        ,\n",
              "        3.        ],\n",
              "       [3.91100649, 3.21591021, 2.98854017, ..., 2.        , 3.        ,\n",
              "        3.        ],\n",
              "       [3.91593122, 3.24268207, 3.08255897, ..., 0.        , 3.        ,\n",
              "        3.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "ftlgeqEHtXhL",
        "outputId": "9ee46e8b-df4d-4278-ab11-73b02a32f6dc"
      },
      "source": [
        "user_cosine_recsys.evaluate_test(rating_df,copy=True).head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100000it [01:15, 1324.39it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userID</th>\n",
              "      <th>itemID</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>user-cosine</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>196</td>\n",
              "      <td>242</td>\n",
              "      <td>3</td>\n",
              "      <td>881250949</td>\n",
              "      <td>4.025213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>186</td>\n",
              "      <td>302</td>\n",
              "      <td>3</td>\n",
              "      <td>891717742</td>\n",
              "      <td>4.142828</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>22</td>\n",
              "      <td>377</td>\n",
              "      <td>1</td>\n",
              "      <td>878887116</td>\n",
              "      <td>1.922080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>244</td>\n",
              "      <td>51</td>\n",
              "      <td>2</td>\n",
              "      <td>880606923</td>\n",
              "      <td>3.431884</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>166</td>\n",
              "      <td>346</td>\n",
              "      <td>1</td>\n",
              "      <td>886397596</td>\n",
              "      <td>3.424963</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   userID  itemID  rating  timestamp  user-cosine\n",
              "0     196     242       3  881250949     4.025213\n",
              "1     186     302       3  891717742     4.142828\n",
              "2      22     377       1  878887116     1.922080\n",
              "3     244      51       2  880606923     3.431884\n",
              "4     166     346       1  886397596     3.424963"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xKrNxAKt50L"
      },
      "source": [
        "class CrossValidation(object):\n",
        "    def __init__(self, metric, data_path=MOVIELENS_DIR):\n",
        "        \"\"\"\n",
        "        INPUT:\n",
        "            metric: string. from['RMSE','P@K','R@K']\n",
        "        \"\"\"\n",
        "        self.folds = self._getData(MOVIELENS_DIR)\n",
        "        self.metric_name = metric\n",
        "        self.metric = self._getMetric(self.metric_name)\n",
        "        \n",
        "    def _getMetric(self, metric_name):\n",
        "        \"\"\"\n",
        "        Don't change this\n",
        "        \"\"\"\n",
        "        switcher = {\n",
        "            'RMSE': self.rmse,\n",
        "            'P@K': self.patk,\n",
        "            'R@K': self.ratk,\n",
        "        }\n",
        "        \n",
        "        return switcher[metric_name]\n",
        "    \n",
        "    @staticmethod\n",
        "    def rmse(data, k, num_users, num_items, pred, true='rating'):\n",
        "        \"\"\"\n",
        "        data: pandas DataFrame. \n",
        "        pred: string. Column name that corresponding to the prediction\n",
        "        true: string. Column name that corresponding to the true rating\n",
        "        \"\"\"\n",
        "        return sqrt(mean_squared_error(data[pred], data[true]))\n",
        "    \n",
        "    # Precision at k\n",
        "    def patk(self, data, k, num_users, num_items, pred, true='rating'):\n",
        "        \"\"\"\n",
        "        data: pandas DataFrame. \n",
        "        k: top-k items retrived\n",
        "        pred: string. Column name that corresponding to the prediction\n",
        "        true: string. Column name that corresponding to the true rating\n",
        "        \"\"\"\n",
        "        prediction = self.getMatrix(data, num_users, num_items, pred)\n",
        "        testSet =  self.getMatrix(data, num_users, num_items, true)\n",
        "    \n",
        "        # Initialize sum and count vars for average calculation\n",
        "        sumPrecisions = 0\n",
        "        countPrecisions = 0\n",
        "\n",
        "        # Define function for converting 1-5 rating to 0/1 (like / don't like)\n",
        "        vf = np.vectorize(lambda x: 1 if x >= 4 else 0)\n",
        "\n",
        "        for userID in range(num_users):\n",
        "            # Pick top K based on predicted rating\n",
        "            userVector = prediction[userID,:]\n",
        "            topK = nlargest(k, range(len(userVector)), userVector.take)\n",
        "\n",
        "            # Convert test set ratings to like / don't like\n",
        "            userTestVector = vf(testSet[userID,:]).nonzero()[0]\n",
        "\n",
        "            # Calculate precision\n",
        "            precision = float(len([item for item in topK if item in userTestVector]))/len(topK)\n",
        "\n",
        "            # Update sum and count\n",
        "            sumPrecisions += precision\n",
        "            countPrecisions += 1\n",
        "\n",
        "        # Return average P@k\n",
        "        return float(sumPrecisions)/countPrecisions\n",
        "    \n",
        "    # Recall at k\n",
        "    def ratk(self, data, k, num_users, num_items, pred, true='rating'):\n",
        "        \"\"\"\n",
        "        data: pandas DataFrame. \n",
        "        k: top-k items relevant\n",
        "        pred: string. Column name that corresponding to the prediction\n",
        "        true: string. Column name that corresponding to the true rating\n",
        "        \"\"\"\n",
        "        prediction = self.getMatrix(data, num_users, num_items, pred)\n",
        "        testSet =  self.getMatrix(data, num_users, num_items, true)\n",
        "        # Initialize sum and count vars for average calculation\n",
        "        sumRecalls = 0\n",
        "        countRecalls = 0\n",
        "\n",
        "        # Define function for converting 1-5 rating to 0/1 (like / don't like)\n",
        "        vf = np.vectorize(lambda x: 1 if x >= 4 else 0)\n",
        "\n",
        "        for userID in range(num_users):\n",
        "            # Pick top K based on predicted rating\n",
        "            userVector = prediction[userID,:]\n",
        "            topK = nlargest(k, range(len(userVector)), userVector.take)\n",
        "\n",
        "            # Convert test set ratings to like / don't like\n",
        "            userTestVector = vf(testSet[userID,:]).nonzero()[0]\n",
        "\n",
        "            # Ignore user if has no ratings in the test set\n",
        "            if (len(userTestVector) == 0):\n",
        "                continue\n",
        "\n",
        "            # Calculate recall\n",
        "            recall = float(len([item for item in topK if item in userTestVector]))/len(userTestVector)\n",
        "\n",
        "            # Update sum and count\n",
        "            sumRecalls += recall\n",
        "            countRecalls += 1\n",
        "\n",
        "        # Return average R@k\n",
        "        return float(sumRecalls)/countRecalls\n",
        "    \n",
        "    @staticmethod\n",
        "    def getMatrix(rating_df, num_users, num_items, column_name):\n",
        "        matrix = np.zeros((num_users, num_items))\n",
        "    \n",
        "        for (index, userID, itemID, value) in rating_df[['userID','itemID', column_name]].itertuples():\n",
        "            matrix[userID-1, itemID-1] = value\n",
        "            \n",
        "        return matrix\n",
        "    \n",
        "    @staticmethod\n",
        "    def _getData(data_path):\n",
        "        \"\"\"\n",
        "        Don't change this function\n",
        "        \"\"\"\n",
        "        folds = []\n",
        "        data_types = ['u{0}.base','u{0}.test']\n",
        "        for i in range(1,6):\n",
        "            train_set = getData(data_path, data_types[0].format(i))\n",
        "            test_set = getData(data_path, data_types[1].format(i))\n",
        "            folds.append([train_set, test_set])\n",
        "        return folds\n",
        "    \n",
        "    def run(self, algorithms, num_users, num_items, k=1):\n",
        "        \"\"\"\n",
        "        5-fold cross-validation\n",
        "        algorithms: list. a list of algorithms. \n",
        "                    eg: [user_cosine_recsys, item_euclidean_recsys]\n",
        "        \"\"\"\n",
        "        \n",
        "        scores = {}\n",
        "        for algorithm in algorithms:\n",
        "            print('Processing algorithm {0}'.format(algorithm.getPredColName()))\n",
        "            fold_scores = []\n",
        "            for fold in self.folds:\n",
        "                algorithm.reset()\n",
        "                algorithm.predict_all(fold[0], num_users, num_items)\n",
        "                prediction = algorithm.evaluate_test(fold[1])\n",
        "                pred_col = algorithm.getPredColName()\n",
        "                fold_scores.append(self.metric(prediction, k, num_users, num_items, pred_col))\n",
        "                \n",
        "            mean = np.mean(fold_scores)\n",
        "            ci_low, ci_high = stats.t.interval(0.95, len(fold_scores)-1, loc=mean, scale=stats.sem(fold_scores))\n",
        "            scores[algorithm.getPredColName()] = [fold_scores, mean, ci_low, ci_high]\n",
        "            \n",
        "        results = scores    \n",
        "    \n",
        "        return results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbF_3ordt52k"
      },
      "source": [
        "# How to use CrossValidation Class?\n",
        "# 1. gather your algorithms in previous steps.\n",
        "algorithm_instances = [user_cosine_recsys,\n",
        "                       item_cosine_recsys]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gm2eTHQjt552"
      },
      "source": [
        "# 2. Instantiate a CrossValidation instance and assign the measurement that you want to use\n",
        "# RMSE, P@K, R@K\n",
        "# Precision at K in this example\n",
        "cv_patk = CrossValidation('RMSE')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Raif1wUfuNRP",
        "outputId": "8bf73376-d9b3-4cf0-c0a1-ba04f86d9557"
      },
      "source": [
        "# 3. Run CV by giving:\n",
        "#    1> algorithms just gathered\n",
        "#    2> number of users in the full dataset\n",
        "#    3> number of items in the full dataset\n",
        "#    4> precision or recall at K need a K value, so k=5 means precision at 5 in this example\n",
        "# Results include independent results from 5 folds, their mean, and confidence interval.\n",
        "cv_patk.run(algorithm_instances, num_users, num_items, k=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm user-cosine\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:06, 2875.89it/s]\n",
            "20000it [00:07, 2815.24it/s]\n",
            "20000it [00:07, 2786.51it/s]\n",
            "20000it [00:06, 2858.95it/s]\n",
            "20000it [00:07, 2832.40it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm item-cosine\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:06, 2876.41it/s]\n",
            "20000it [00:06, 2875.88it/s]\n",
            "20000it [00:07, 2822.55it/s]\n",
            "20000it [00:06, 2866.81it/s]\n",
            "20000it [00:06, 2894.72it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'item-cosine': [[1.0334307063086856,\n",
              "   1.0169957595085215,\n",
              "   1.0045122531086308,\n",
              "   1.0099161642550833,\n",
              "   1.0111907186985918],\n",
              "  1.0152091203759024,\n",
              "  1.0014131747526513,\n",
              "  1.0290050659991534],\n",
              " 'user-cosine': [[1.026449013124381,\n",
              "   1.0214387664779507,\n",
              "   1.0132940326457187,\n",
              "   1.0094003999022947,\n",
              "   1.0161883961525586],\n",
              "  1.0173541216605808,\n",
              "  1.009013080226148,\n",
              "  1.0256951630950135]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPddj53quNTb"
      },
      "source": [
        "q3 = dataPreprocessor(rating_df, num_users, num_items)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PO_MyImkuNVg"
      },
      "source": [
        "temp_matrix = np.zeros(q3.shape)\n",
        "temp_matrix[q3.nonzero()] = 1 \n",
        "sumperrow = np.sum(temp_matrix, axis=1)\n",
        "averagenumberofratingsperuser = (sumperrow.sum())/943\n",
        "averagenumberofratingsperitem = (sumperrow.sum())/1682"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQkUqCSguNYu",
        "outputId": "3d7f3237-bbbd-4a3a-f989-10087d0e2fcb"
      },
      "source": [
        "averagenumberofratingsperitem"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "59.45303210463734"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CE9M__GEuNbC",
        "outputId": "5687b86c-75c0-4eae-d59c-1f218f8e61bc"
      },
      "source": [
        "averagenumberofratingsperuser"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "106.04453870625663"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bAcBE6lcrqr"
      },
      "source": [
        "Analysis: \n",
        "* The following values are RMSE average, low CI and high CI\n",
        "'item-cosine': [ 1.020, 1.006, 1.033,\n",
        "'user-cosine': [ 1.017, 1.009, 1.025,\n",
        "\n",
        "* If we see the RMSE results the user is performing slightly better because in our case the average number of ratings per user 106 is more than the average number of ratings per item 59. So while using similarity metrics in case of users we have more rich vectors to find out the similar ones. so better predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9ktVge-crqr"
      },
      "source": [
        "### Q4. Performance Comparison (not auto-graded)\r\n",
        "\r\n",
        "(a) Please use the given class **CrossValidation** to compare all the recommenders in Q1, Q2 and Q3 (using cosine similarity) on RMSE, P@k, and R@k. Show the cleanly formatted results of this comparison.\r\n",
        "\r\n",
        "(b) Some baselines cannot be evaluated with some metrics? Which ones and why?\r\n",
        "\r\n",
        "(c) What is the best algorithm for each of RMSE, P@k, and R@k? Can you explain why this may be?\r\n",
        "\r\n",
        "(d) Does good performance on RMSE imply good performance on ranking metrics and vice versa? Why / why not?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jx-mJY8suNlq"
      },
      "source": [
        "# 1. gather your algorithms in previous steps.\n",
        "algorithm_instances = [popularity_recsys, \n",
        "                       average_user_rating_recsys, \n",
        "                       user_cosine_recsys,\n",
        "                       item_cosine_recsys]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tY1unenXuNgi"
      },
      "source": [
        "cv_rmse = CrossValidation('RMSE')\r\n",
        "cv_pk = CrossValidation('P@K')\r\n",
        "cv_rk = CrossValidation('R@K')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLAOG0KyCaN-",
        "outputId": "7f910ac7-f5c5-4901-e7b1-512df348cae2"
      },
      "source": [
        "scores_rmse = cv_rmse.run(algorithm_instances, num_users, num_items,k=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm popularity\n",
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:07, 2846.17it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:07, 2780.78it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:06, 2875.80it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:06, 2885.33it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:07, 2854.62it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm useraverage\n",
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:07, 2845.82it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:07, 2838.74it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2110.67it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:07, 2839.02it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:06, 2888.75it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm user-cosine\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:07, 2823.72it/s]\n",
            "20000it [00:06, 2892.34it/s]\n",
            "20000it [00:07, 2813.77it/s]\n",
            "20000it [00:06, 2863.85it/s]\n",
            "20000it [00:07, 2817.89it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm item-cosine\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:07, 2847.98it/s]\n",
            "20000it [00:06, 2871.49it/s]\n",
            "20000it [00:07, 2838.15it/s]\n",
            "20000it [00:07, 2776.02it/s]\n",
            "20000it [00:06, 2884.90it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCpKMhMuCaK8",
        "outputId": "8b3477ce-5e09-4488-c8bd-a9b67b8a8a95"
      },
      "source": [
        "scores_pk = cv_pk.run(algorithm_instances, num_users, num_items,k=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm popularity\n",
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:07, 2822.54it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:07, 2844.29it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:07, 2754.42it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:07, 2817.68it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:07, 2856.74it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm useraverage\n",
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:07, 2838.73it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:07, 2813.92it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:06, 2877.22it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:07, 2823.68it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:07, 2825.01it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm user-cosine\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:07, 2789.43it/s]\n",
            "20000it [00:06, 2874.61it/s]\n",
            "20000it [00:06, 2865.02it/s]\n",
            "20000it [00:07, 2856.41it/s]\n",
            "20000it [00:07, 2805.07it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm item-cosine\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:06, 2858.07it/s]\n",
            "20000it [00:07, 2825.32it/s]\n",
            "20000it [00:07, 2836.51it/s]\n",
            "20000it [00:06, 2884.14it/s]\n",
            "20000it [00:06, 2890.40it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4eEUjcOutaZ",
        "outputId": "a900f7a3-4c9a-4d05-987f-06eeb8766717"
      },
      "source": [
        "scores_rk = cv_rk.run(algorithm_instances, num_users, num_items,k=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm popularity\n",
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:06, 2873.60it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:07, 2739.31it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:06, 2858.68it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:06, 2863.95it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:06, 2874.45it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm useraverage\n",
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:06, 2886.90it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:07, 2823.86it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:06, 2865.69it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:06, 2894.88it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:06, 2918.72it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm user-cosine\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:07, 2856.99it/s]\n",
            "20000it [00:06, 2891.51it/s]\n",
            "20000it [00:07, 2840.51it/s]\n",
            "20000it [00:07, 2809.49it/s]\n",
            "20000it [00:06, 2874.96it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm item-cosine\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:07, 2814.74it/s]\n",
            "20000it [00:06, 2871.32it/s]\n",
            "20000it [00:06, 2911.74it/s]\n",
            "20000it [00:06, 2858.35it/s]\n",
            "20000it [00:06, 2909.89it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJuWVAoPCth0"
      },
      "source": [
        "Analysis:\r\n",
        "\r\n",
        "(A) \r\n",
        "For each of the metrics the three values are Average, Low CI and high CI.\r\n",
        "             Ave LowCI HIgh CI\r\n",
        "\r\n",
        "```\r\n",
        "* RMSE {'item-cosine': [ 1.020, 1.006, 1.033,\r\n",
        "'popularity': [ 3.159, 3.139, 3.178,\r\n",
        "'user-cosine': [ 1.017, 1.009, 1.025,\r\n",
        "'useraverage': [ 1.043, 1.028, 1.058,}\r\n",
        "P@K\r\n",
        "{'item-cosine': [ 0.532, 0.383, 0.680,\r\n",
        "'popularity': [ 0.550, 0.405, 0.695,\r\n",
        "'user-cosine': [ 0.555, 0.409, 0.702,\r\n",
        "'useraverage': [ 0.473, 0.341, 0.605]}\r\n",
        "R@K\r\n",
        "{'item-cosine': [ 0.474, 0.353, 0.596],\r\n",
        "'popularity': [ 0.484, 0.367, 0.601,\r\n",
        "'user-cosine': [ 0.486, 0.369, 0.603,\r\n",
        "'useraverage': [ 0.441, 0.329, 0.553}\r\n",
        "```\r\n",
        "\r\n",
        "(B)\r\n",
        "Some baselines cannot be evaluated with some metrics? Which ones and why?\r\n",
        "\r\n",
        "* For User Average This predicts the same average rating for all the movies for a user (for the movies there are no ratings). In this case rank based metrics P@k and R@k cannot be evaluated. For popularity, We cannot use RMSE for popularity becuase the popularity values in this case are between 0 to 1 (because we are not taking the exact rating for calculation we have only taken if the user liked(rating > 4) or not) but the test ratings are from 1 to 5. so RMSE cannot be evaluated\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "(C)\r\n",
        "What is the best algorithm for each of RMSE, P@k, and R@k? Can you explain why this may be?\r\n",
        "\r\n",
        "* P@k and R@k the evaluations are based on ranking (we need to recommend most relavant to each user). For better ranking the similarity metrics are most suitable because the popularity and average are not persnolized to each user. From the results we can say that user cosine average performed slighlty better in both P@K and R@K. For RMSE cosine similarity measures work better becuase the similarity measures predict the rating based on ratings of most similar users or items. We can also see that in case of RMSE similarity measure have better performed.\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "(D)\r\n",
        "Does good performance on RMSE imply good performance on ranking metrics and vice versa? Why / why not?\r\n",
        "\r\n",
        "* No good performance of RMSE doesn't imply good performace on ranking metrics. Becuase RMSE is calulated for all the user ratings wheter he liked it or not irrespective of their rankings. So good RMSE may come at expense of bad ranking of top K. Similarly, in case of ranking metrics we are only concerned about ranking in top k and have no clue about others. So good performance of ranking doesn't necasarily mean good performance of RMSE."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abPlEauBcrqv"
      },
      "source": [
        "### Q5. Similarity Evaluation (not auto-graded)\r\n",
        "(a) Go through the list of movies and pick three not-so-popular movies that you know well. I.e., do not choose \"Star Wars\" and note that we expect everyone in the class to have chosen different movies. For each of these three movies, list the top 5 most similar movie names according to item-item cosine similarity (you might use a function like numpy argsort).\r\n",
        "\r\n",
        "(b) Can you justify these similarities? Why or why not? Consider that similarity is determined indirectly by users who rated both items."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5nYfZWGWvaJU",
        "outputId": "0ea9cd2a-6cf0-4584-8a3f-6f60b4419083"
      },
      "source": [
        "q5 = dataPreprocessor(rating_df, num_users, num_items)\n",
        "q5 = q5.transpose()  \n",
        "ii_similarity = 1 - pairwise_distances(q5, metric='cosine')\n",
        "ii_similarity"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.        , 0.40238218, 0.33024479, ..., 0.        , 0.04718307,\n",
              "        0.04718307],\n",
              "       [0.40238218, 1.        , 0.27306918, ..., 0.        , 0.07829936,\n",
              "        0.07829936],\n",
              "       [0.33024479, 0.27306918, 1.        , ..., 0.        , 0.        ,\n",
              "        0.09687505],\n",
              "       ...,\n",
              "       [0.        , 0.        , 0.        , ..., 1.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.04718307, 0.07829936, 0.        , ..., 0.        , 1.        ,\n",
              "        0.        ],\n",
              "       [0.04718307, 0.07829936, 0.09687505, ..., 0.        , 0.        ,\n",
              "        1.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "8kYF0YMrcrqv",
        "outputId": "92e18c9f-2607-40e9-93b2-1f115af8968d"
      },
      "source": [
        "fieldsMovies = ['movieID', 'movieTitle', 'releaseDate', 'videoReleaseDate', 'IMDbURL', 'unknown', 'action', 'adventure',\n",
        "                'animation', 'childrens', 'comedy', 'crime', 'documentary', 'drama', 'fantasy', 'filmNoir', 'horror',\n",
        "                'musical', 'mystery', 'romance','sciFi', 'thriller', 'war', 'western']\n",
        "moviesDF = pd.read_csv(os.path.join(MOVIELENS_DIR, 'u.item'), sep='|', names=fieldsMovies, encoding='latin-1')\n",
        "moviesDF.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>movieID</th>\n",
              "      <th>movieTitle</th>\n",
              "      <th>releaseDate</th>\n",
              "      <th>videoReleaseDate</th>\n",
              "      <th>IMDbURL</th>\n",
              "      <th>unknown</th>\n",
              "      <th>action</th>\n",
              "      <th>adventure</th>\n",
              "      <th>animation</th>\n",
              "      <th>childrens</th>\n",
              "      <th>comedy</th>\n",
              "      <th>crime</th>\n",
              "      <th>documentary</th>\n",
              "      <th>drama</th>\n",
              "      <th>fantasy</th>\n",
              "      <th>filmNoir</th>\n",
              "      <th>horror</th>\n",
              "      <th>musical</th>\n",
              "      <th>mystery</th>\n",
              "      <th>romance</th>\n",
              "      <th>sciFi</th>\n",
              "      <th>thriller</th>\n",
              "      <th>war</th>\n",
              "      <th>western</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Toy Story (1995)</td>\n",
              "      <td>01-Jan-1995</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://us.imdb.com/M/title-exact?Toy%20Story%2...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>GoldenEye (1995)</td>\n",
              "      <td>01-Jan-1995</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://us.imdb.com/M/title-exact?GoldenEye%20(...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Four Rooms (1995)</td>\n",
              "      <td>01-Jan-1995</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://us.imdb.com/M/title-exact?Four%20Rooms%...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Get Shorty (1995)</td>\n",
              "      <td>01-Jan-1995</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://us.imdb.com/M/title-exact?Get%20Shorty%...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Copycat (1995)</td>\n",
              "      <td>01-Jan-1995</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://us.imdb.com/M/title-exact?Copycat%20(1995)</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   movieID         movieTitle  releaseDate  ...  thriller war  western\n",
              "0        1   Toy Story (1995)  01-Jan-1995  ...         0   0        0\n",
              "1        2   GoldenEye (1995)  01-Jan-1995  ...         1   0        0\n",
              "2        3  Four Rooms (1995)  01-Jan-1995  ...         1   0        0\n",
              "3        4  Get Shorty (1995)  01-Jan-1995  ...         0   0        0\n",
              "4        5     Copycat (1995)  01-Jan-1995  ...         1   0        0\n",
              "\n",
              "[5 rows x 24 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HY4cdNPlxahO"
      },
      "source": [
        "# Method 1\r\n",
        "def itemTopK(prediction, moviesDataset, itemID, k):\r\n",
        "  # Pick top K based on predicted rating\r\n",
        "  itemVector = prediction[:,itemID-1]\r\n",
        "  topK = nlargest(k+1, range(len(itemVector)), itemVector.take)\r\n",
        "  topK = topK[1:]\r\n",
        "  namesTopK = list(map(lambda x: moviesDataset[moviesDataset.movieID == x+1][\"movieTitle\"].values[0], topK))\r\n",
        "  return namesTopK"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQDD8lUwxjsa",
        "outputId": "89d5f223-141f-4008-b09e-a7cdebbd3d44"
      },
      "source": [
        "itemTopK(ii_similarity, moviesDF, 110, 5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Junior (1994)',\n",
              " 'Angels in the Outfield (1994)',\n",
              " 'Santa Clause, The (1994)',\n",
              " 'Made in America (1993)',\n",
              " 'Corrina, Corrina (1994)']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TzJjeec7yDB6",
        "outputId": "04a09980-a308-4ec2-d8e7-ad25233d811b"
      },
      "source": [
        "itemTopK(ii_similarity, moviesDF, 224, 5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Cold Comfort Farm (1995)',\n",
              " 'Little Odessa (1994)',\n",
              " 'Big Night (1996)',\n",
              " 'Horseman on the Roof, The (Hussard sur le toit, Le) (1995)',\n",
              " 'Looking for Richard (1996)']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5q2LCeTvxJHE",
        "outputId": "920f5146-155b-466c-8e6d-594c70a30fc3"
      },
      "source": [
        "# Method 2\r\n",
        "listindex = [109,223,526,873,1298]\r\n",
        "listmovieid = [110,224,527,874,1299]\r\n",
        "final = np.argsort(ii_similarity, axis=1, kind='quicksort', order=None)[:,1676:1682]\r\n",
        "\r\n",
        "for i in listindex:\r\n",
        "  movielist = final[i]\r\n",
        "  print(\"Top similar movies to\")\r\n",
        "  print(moviesDF.iloc[i,1])\r\n",
        "  print(\"are\")\r\n",
        "\r\n",
        "  for j in movielist:\r\n",
        "      print(moviesDF.iloc[j,1])\r\n",
        "  print(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Top similar movies to\n",
            "Operation Dumbo Drop (1995)\n",
            "are\n",
            "Corrina, Corrina (1994)\n",
            "Made in America (1993)\n",
            "Santa Clause, The (1994)\n",
            "Angels in the Outfield (1994)\n",
            "Junior (1994)\n",
            "Operation Dumbo Drop (1995)\n",
            "\n",
            "\n",
            "Top similar movies to\n",
            "Ridicule (1996)\n",
            "are\n",
            "Looking for Richard (1996)\n",
            "Horseman on the Roof, The (Hussard sur le toit, Le) (1995)\n",
            "Big Night (1996)\n",
            "Little Odessa (1994)\n",
            "Cold Comfort Farm (1995)\n",
            "Ridicule (1996)\n",
            "\n",
            "\n",
            "Top similar movies to\n",
            "Gandhi (1982)\n",
            "are\n",
            "Casablanca (1942)\n",
            "Raiders of the Lost Ark (1981)\n",
            "Forrest Gump (1994)\n",
            "One Flew Over the Cuckoo's Nest (1975)\n",
            "Amadeus (1984)\n",
            "Gandhi (1982)\n",
            "\n",
            "\n",
            "Top similar movies to\n",
            "Career Girls (1997)\n",
            "are\n",
            "In the Company of Men (1997)\n",
            "Ice Storm, The (1997)\n",
            "Ulee's Gold (1997)\n",
            "Kicked in the Head (1997)\n",
            "Steel (1997)\n",
            "Career Girls (1997)\n",
            "\n",
            "\n",
            "Top similar movies to\n",
            "Penny Serenade (1941)\n",
            "are\n",
            "Love in the Afternoon (1957)\n",
            "Laura (1944)\n",
            "Band Wagon, The (1953)\n",
            "Gay Divorcee, The (1934)\n",
            "Charade (1963)\n",
            "Penny Serenade (1941)\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "teiSeJEZcrqx"
      },
      "source": [
        "B) \n",
        "\n",
        "If group of items are similar it means their item vectors are similar. This happens when same user ranked all of the items. In this case the magnitude of their rating doesn't matter becuase we are using cosine metric. only thing which matters if the same users have rated the items or not. For this to happen there could be many reasons like all the movies belonging to a particular genre or all of them have same actor, genre or director.\n",
        "\n",
        "```\n",
        "Justify : \n",
        "Top similar movies to Career Girls (1997)\n",
        "are In the Company of Men (1997)\n",
        "Ice Storm, The (1997)\n",
        "Ulee's Gold (1997)\n",
        "Kicked in the Head (1997)\n",
        "Steel (1997)\n",
        "Career Girls (1997)\n",
        "```\n",
        "\n",
        "All of them have same genre \"DRAMA\" and all of them are released in same year. In fact the movies all released in same year. So DRAMA lovers of 1990's must have rated all the movies.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCXbYsa7crqx"
      },
      "source": [
        "### Q6. Testing with different user types (not auto-graded)\r\n",
        "\r\n",
        "(a) Look at a histogram of the number of ratings per user. (Google for \\scipy histogram\".) Pick a threshold \u001c that you believe divides users with few ratings and those with a moderate to large number of ratings. What \u001c did you choose? Evaluate the RMSE of user-user and item-item collaborative filtering, but in each of the following two cases testing on only users that meet\r\n",
        "the following criteria:\r\n",
        "\r\n",
        "1.   Above threshold \u001c of liked items\r\n",
        "2.   Below threshold \u001c of liked items\r\n",
        "\r\n",
        "For each of user-user and item-item collaborative filtering, are there any di\u000berences between recommender performance for (i) and (ii)? Can you explain these di\u000berences (or the lack thereof)?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4f3sbjHcrqx"
      },
      "source": [
        "q6df = dataPreprocessor(rating_df, num_users, num_items)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pd6hxRtvzP0Y"
      },
      "source": [
        "temp_matrix = np.zeros(q6df.shape)\n",
        "temp_matrix[q6df.nonzero()] = 1 \n",
        "userratingsnumber = np.sum(temp_matrix, axis=1)\n",
        "#userratingsnumber.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "6A85yBIPzP2p",
        "outputId": "07af6c14-6176-4801-b4fe-aeb32f401015"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.hist(userratingsnumber, bins=50)\n",
        "plt.title(\"Histogram with 'auto' bins\")\n",
        "plt.show()\n",
        "#userratingsnumber"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sY_MAGUPzP5o",
        "outputId": "85f7f1de-6df1-4a74-851a-94eb5892c2c7"
      },
      "source": [
        "np.percentile(userratingsnumber,75)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "148.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c109tvkczP8E",
        "outputId": "d1aba0a0-2f72-4ee1-f929-eefd340cf600"
      },
      "source": [
        "thresholdbelow = np.argwhere(userratingsnumber <= 148).flatten()\n",
        "len(thresholdbelow)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "709"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thDm5f32zP_Y",
        "outputId": "c92c7b4f-f409-4ad4-b6e7-be9c3cdc0ad9"
      },
      "source": [
        "thresholdabove = np.argwhere(userratingsnumber > 148).flatten()\n",
        "len(thresholdabove)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "234"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQf_R-cazvSf"
      },
      "source": [
        "class CrossValidationq6above(object):\n",
        "    def __init__(self, metric, data_path=MOVIELENS_DIR):\n",
        "        \"\"\"\n",
        "            INPUT:\n",
        "                metric: string. from['RMSE','P@K','R@K']\n",
        "        \"\"\"\n",
        "        self.folds = self._getData(MOVIELENS_DIR)\n",
        "        self.metric_name = metric\n",
        "        self.metric = self._getMetric(self.metric_name)\n",
        "        \n",
        "    def _getMetric(self, metric_name):\n",
        "        \"\"\"\n",
        "            Don't change this\n",
        "        \"\"\"\n",
        "        switcher = {\n",
        "            'RMSE': self.rmse,\n",
        "            'P@K': self.patk,\n",
        "            'R@K': self.ratk,\n",
        "        }\n",
        "        \n",
        "        return switcher[metric_name]\n",
        "    \n",
        "    @staticmethod\n",
        "    def rmse(data, k, num_users, num_items, pred, true='rating'):\n",
        "        \"\"\"\n",
        "            data: pandas DataFrame. \n",
        "            pred: string. Column name that corresponding to the prediction\n",
        "            true: string. Column name that corresponding to the true rating\n",
        "        \"\"\"\n",
        "        return sqrt(mean_squared_error(data[pred], data[true]))\n",
        "    \n",
        "    # Precision at k\n",
        "    def patk(self, data, k, num_users, num_items, pred, true='rating'):\n",
        "        \"\"\"\n",
        "            data: pandas DataFrame. \n",
        "            k: top-k items retrived\n",
        "            pred: string. Column name that corresponding to the prediction\n",
        "            true: string. Column name that corresponding to the true rating\n",
        "        \"\"\"\n",
        "        prediction = self.getMatrix(data, num_users, num_items, pred)\n",
        "        testSet =  self.getMatrix(data, num_users, num_items, true)\n",
        "    \n",
        "        # Initialize sum and count vars for average calculation\n",
        "        sumPrecisions = 0\n",
        "        countPrecisions = 0\n",
        "\n",
        "        # Define function for converting 1-5 rating to 0/1 (like / don't like)\n",
        "        vf = np.vectorize(lambda x: 1 if x >= 4 else 0)\n",
        "\n",
        "        for userID in range(num_users):\n",
        "            # Pick top K based on predicted rating\n",
        "            userVector = prediction[userID,:]\n",
        "            topK = nlargest(k, range(len(userVector)), userVector.take)\n",
        "\n",
        "            # Convert test set ratings to like / don't like\n",
        "            userTestVector = vf(testSet[userID,:]).nonzero()[0]\n",
        "\n",
        "            # Calculate precision\n",
        "            precision = float(len([item for item in topK if item in userTestVector]))/len(topK)\n",
        "\n",
        "            # Update sum and count\n",
        "            sumPrecisions += precision\n",
        "            countPrecisions += 1\n",
        "\n",
        "        # Return average P@k\n",
        "        return float(sumPrecisions)/countPrecisions\n",
        "    \n",
        "    # Recall at k\n",
        "    def ratk(self, data, k, num_users, num_items, pred, true='rating'):\n",
        "        \"\"\"\n",
        "            data: pandas DataFrame. \n",
        "            k: top-k items relevant\n",
        "            pred: string. Column name that corresponding to the prediction\n",
        "            true: string. Column name that corresponding to the true rating\n",
        "        \"\"\"\n",
        "        prediction = self.getMatrix(data, num_users, num_items, pred)\n",
        "        testSet =  self.getMatrix(data, num_users, num_items, true)\n",
        "        # Initialize sum and count vars for average calculation\n",
        "        sumRecalls = 0\n",
        "        countRecalls = 0\n",
        "\n",
        "        # Define function for converting 1-5 rating to 0/1 (like / don't like)\n",
        "        vf = np.vectorize(lambda x: 1 if x >= 4 else 0)\n",
        "\n",
        "        for userID in range(num_users):\n",
        "            # Pick top K based on predicted rating\n",
        "            userVector = prediction[userID,:]\n",
        "            topK = nlargest(k, range(len(userVector)), userVector.take)\n",
        "\n",
        "            # Convert test set ratings to like / don't like\n",
        "            userTestVector = vf(testSet[userID,:]).nonzero()[0]\n",
        "\n",
        "            # Ignore user if has no ratings in the test set\n",
        "            if (len(userTestVector) == 0):\n",
        "                continue\n",
        "\n",
        "            # Calculate recall\n",
        "            recall = float(len([item for item in topK if item in userTestVector]))/len(userTestVector)\n",
        "\n",
        "            # Update sum and count\n",
        "            sumRecalls += recall\n",
        "            countRecalls += 1\n",
        "\n",
        "        # Return average R@k\n",
        "        return float(sumRecalls)/countRecalls\n",
        "    \n",
        "    @staticmethod\n",
        "    def getMatrix(rating_df, num_users, num_items, column_name):\n",
        "        matrix = np.zeros((num_users, num_items))\n",
        "    \n",
        "        for (index, userID, itemID, value) in rating_df[['userID','itemID', column_name]].itertuples():\n",
        "            matrix[userID-1, itemID-1] = value\n",
        "            \n",
        "        return matrix\n",
        "    \n",
        "    @staticmethod\n",
        "    def _getData(data_path):\n",
        "        \"\"\"\n",
        "            Don't change this function\n",
        "        \"\"\"\n",
        "        folds = []\n",
        "        data_types = ['u{0}.base','u{0}.test']\n",
        "        for i in range(1,6):\n",
        "            train_set = getData(data_path, data_types[0].format(i))\n",
        "            train_set = train_set.loc[train_set['userID'].isin(thresholdabove)]\n",
        "            \n",
        "            test_set = getData(data_path, data_types[1].format(i))\n",
        "            test_set = test_set.loc[test_set['userID'].isin(thresholdabove)]\n",
        "            \n",
        "            folds.append([train_set, test_set])\n",
        "        return folds\n",
        "    \n",
        "    def run(self, algorithms, num_users, num_items, k=1):\n",
        "        \"\"\"\n",
        "            5-fold cross-validation\n",
        "            algorithms: list. a list of algorithms. \n",
        "                        eg: [user_cosine_recsys, item_euclidean_recsys]\n",
        "        \"\"\"\n",
        "        \n",
        "        scores = {}\n",
        "        for algorithm in algorithms:\n",
        "            print('Processing algorithm {0}'.format(algorithm.getPredColName()))\n",
        "            fold_scores = []\n",
        "            for fold in self.folds:\n",
        "                algorithm.reset()\n",
        "                algorithm.predict_all(fold[0], num_users, num_items)\n",
        "                prediction = algorithm.evaluate_test(fold[1])\n",
        "                pred_col = algorithm.getPredColName()\n",
        "                fold_scores.append(self.metric(prediction, k, num_users, num_items, pred_col))\n",
        "                \n",
        "            mean = np.mean(fold_scores)\n",
        "            ci_low, ci_high = stats.t.interval(0.95, len(fold_scores)-1, loc=mean, scale=stats.sem(fold_scores))\n",
        "            scores[algorithm.getPredColName()] = [fold_scores, mean, ci_low, ci_high]\n",
        "            \n",
        "        results = scores    \n",
        "    \n",
        "        return results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gMBqwk_zvVL"
      },
      "source": [
        "item_cosine_recsys = SimBasedRecSys('item','cosine')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tgVRxclzvX1"
      },
      "source": [
        "user_cosine_recsys = SimBasedRecSys('user','cosine')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BeMbYA0Zzval"
      },
      "source": [
        "# 1. gather your algorithms in previous steps.\n",
        "algorithm_instances_Q6 = [user_cosine_recsys,\n",
        "                          item_cosine_recsys]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqdNKuETzvfD",
        "outputId": "ccb32379-1c49-458d-80d1-e051005cb79e"
      },
      "source": [
        "cv_patk = CrossValidationq6above('RMSE')\n",
        "cv_patk.run(algorithm_instances_Q6, num_users, num_items)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm user-cosine\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:86: RuntimeWarning: invalid value encountered in true_divide\n",
            "5690it [00:01, 3144.36it/s]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:86: RuntimeWarning: invalid value encountered in true_divide\n",
            "5970it [00:01, 3284.12it/s]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:86: RuntimeWarning: invalid value encountered in true_divide\n",
            "5067it [00:01, 3154.65it/s]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:86: RuntimeWarning: invalid value encountered in true_divide\n",
            "4833it [00:01, 3044.12it/s]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:86: RuntimeWarning: invalid value encountered in true_divide\n",
            "4869it [00:01, 3323.75it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm item-cosine\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:100: RuntimeWarning: invalid value encountered in true_divide\n",
            "5690it [00:01, 2957.34it/s]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:100: RuntimeWarning: invalid value encountered in true_divide\n",
            "5970it [00:01, 3103.08it/s]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:100: RuntimeWarning: invalid value encountered in true_divide\n",
            "5067it [00:01, 3085.33it/s]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:100: RuntimeWarning: invalid value encountered in true_divide\n",
            "4833it [00:01, 2910.88it/s]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:100: RuntimeWarning: invalid value encountered in true_divide\n",
            "4869it [00:01, 3014.85it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'item-cosine': [[1.0320705332140439,\n",
              "   1.0303344025835743,\n",
              "   1.009264637240564,\n",
              "   1.013847317185086,\n",
              "   1.0242143187710053],\n",
              "  1.0219462417988545,\n",
              "  1.0094611518447707,\n",
              "  1.0344313317529383],\n",
              " 'user-cosine': [[1.0503720301028903,\n",
              "   1.0760128059562617,\n",
              "   1.0570055555699578,\n",
              "   1.054340869987063,\n",
              "   1.0468077895648276],\n",
              "  1.0569078102362,\n",
              "  1.042800757991966,\n",
              "  1.0710148624804339]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdTY1zLkzviQ"
      },
      "source": [
        "class CrossValidationq6below(object):\n",
        "    def __init__(self, metric, data_path=MOVIELENS_DIR):\n",
        "        \"\"\"\n",
        "            INPUT:\n",
        "                metric: string. from['RMSE','P@K','R@K']\n",
        "        \"\"\"\n",
        "        self.folds = self._getData(MOVIELENS_DIR)\n",
        "        self.metric_name = metric\n",
        "        self.metric = self._getMetric(self.metric_name)\n",
        "        \n",
        "    def _getMetric(self, metric_name):\n",
        "        \"\"\"\n",
        "            Don't change this\n",
        "        \"\"\"\n",
        "        switcher = {\n",
        "            'RMSE': self.rmse,\n",
        "            'P@K': self.patk,\n",
        "            'R@K': self.ratk,\n",
        "        }\n",
        "        \n",
        "        return switcher[metric_name]\n",
        "    \n",
        "    @staticmethod\n",
        "    def rmse(data, k, num_users, num_items, pred, true='rating'):\n",
        "        \"\"\"\n",
        "            data: pandas DataFrame. \n",
        "            pred: string. Column name that corresponding to the prediction\n",
        "            true: string. Column name that corresponding to the true rating\n",
        "        \"\"\"\n",
        "        return sqrt(mean_squared_error(data[pred], data[true]))\n",
        "    \n",
        "    # Precision at k\n",
        "    def patk(self, data, k, num_users, num_items, pred, true='rating'):\n",
        "        \"\"\"\n",
        "            data: pandas DataFrame. \n",
        "            k: top-k items retrived\n",
        "            pred: string. Column name that corresponding to the prediction\n",
        "            true: string. Column name that corresponding to the true rating\n",
        "        \"\"\"\n",
        "        prediction = self.getMatrix(data, num_users, num_items, pred)\n",
        "        testSet =  self.getMatrix(data, num_users, num_items, true)\n",
        "    \n",
        "        # Initialize sum and count vars for average calculation\n",
        "        sumPrecisions = 0\n",
        "        countPrecisions = 0\n",
        "\n",
        "        # Define function for converting 1-5 rating to 0/1 (like / don't like)\n",
        "        vf = np.vectorize(lambda x: 1 if x >= 4 else 0)\n",
        "\n",
        "        for userID in range(num_users):\n",
        "            # Pick top K based on predicted rating\n",
        "            userVector = prediction[userID,:]\n",
        "            topK = nlargest(k, range(len(userVector)), userVector.take)\n",
        "\n",
        "            # Convert test set ratings to like / don't like\n",
        "            userTestVector = vf(testSet[userID,:]).nonzero()[0]\n",
        "\n",
        "            # Calculate precision\n",
        "            precision = float(len([item for item in topK if item in userTestVector]))/len(topK)\n",
        "\n",
        "            # Update sum and count\n",
        "            sumPrecisions += precision\n",
        "            countPrecisions += 1\n",
        "\n",
        "        # Return average P@k\n",
        "        return float(sumPrecisions)/countPrecisions\n",
        "    \n",
        "    # Recall at k\n",
        "    def ratk(self, data, k, num_users, num_items, pred, true='rating'):\n",
        "        \"\"\"\n",
        "            data: pandas DataFrame. \n",
        "            k: top-k items relevant\n",
        "            pred: string. Column name that corresponding to the prediction\n",
        "            true: string. Column name that corresponding to the true rating\n",
        "        \"\"\"\n",
        "        prediction = self.getMatrix(data, num_users, num_items, pred)\n",
        "        testSet =  self.getMatrix(data, num_users, num_items, true)\n",
        "        # Initialize sum and count vars for average calculation\n",
        "        sumRecalls = 0\n",
        "        countRecalls = 0\n",
        "\n",
        "        # Define function for converting 1-5 rating to 0/1 (like / don't like)\n",
        "        vf = np.vectorize(lambda x: 1 if x >= 4 else 0)\n",
        "\n",
        "        for userID in range(num_users):\n",
        "            # Pick top K based on predicted rating\n",
        "            userVector = prediction[userID,:]\n",
        "            topK = nlargest(k, range(len(userVector)), userVector.take)\n",
        "\n",
        "            # Convert test set ratings to like / don't like\n",
        "            userTestVector = vf(testSet[userID,:]).nonzero()[0]\n",
        "\n",
        "            # Ignore user if has no ratings in the test set\n",
        "            if (len(userTestVector) == 0):\n",
        "                continue\n",
        "\n",
        "            # Calculate recall\n",
        "            recall = float(len([item for item in topK if item in userTestVector]))/len(userTestVector)\n",
        "\n",
        "            # Update sum and count\n",
        "            sumRecalls += recall\n",
        "            countRecalls += 1\n",
        "\n",
        "        # Return average R@k\n",
        "        return float(sumRecalls)/countRecalls\n",
        "    \n",
        "    @staticmethod\n",
        "    def getMatrix(rating_df, num_users, num_items, column_name):\n",
        "        matrix = np.zeros((num_users, num_items))\n",
        "    \n",
        "        for (index, userID, itemID, value) in rating_df[['userID','itemID', column_name]].itertuples():\n",
        "            matrix[userID-1, itemID-1] = value\n",
        "            \n",
        "        return matrix\n",
        "    \n",
        "    @staticmethod\n",
        "    def _getData(data_path):\n",
        "        \"\"\"\n",
        "            Don't change this function\n",
        "        \"\"\"\n",
        "        folds = []\n",
        "        data_types = ['u{0}.base','u{0}.test']\n",
        "        for i in range(1,6):\n",
        "            train_set = getData(data_path, data_types[0].format(i))\n",
        "            train_set = train_set.loc[train_set['userID'].isin(thresholdbelow)]\n",
        "            \n",
        "            test_set = getData(data_path, data_types[1].format(i))\n",
        "            test_set = test_set.loc[test_set['userID'].isin(thresholdbelow)]\n",
        "            \n",
        "            folds.append([train_set, test_set])\n",
        "        return folds\n",
        "    \n",
        "    def run(self, algorithms, num_users, num_items, k=1):\n",
        "        \"\"\"\n",
        "            5-fold cross-validation\n",
        "            algorithms: list. a list of algorithms. \n",
        "                        eg: [user_cosine_recsys, item_euclidean_recsys]\n",
        "        \"\"\"\n",
        "        \n",
        "        scores = {}\n",
        "        for algorithm in algorithms:\n",
        "            print('Processing algorithm {0}'.format(algorithm.getPredColName()))\n",
        "            fold_scores = []\n",
        "            for fold in self.folds:\n",
        "                algorithm.reset()\n",
        "                algorithm.predict_all(fold[0], num_users, num_items)\n",
        "                prediction = algorithm.evaluate_test(fold[1])\n",
        "                pred_col = algorithm.getPredColName()\n",
        "                fold_scores.append(self.metric(prediction, k, num_users, num_items, pred_col))\n",
        "                \n",
        "            mean = np.mean(fold_scores)\n",
        "            ci_low, ci_high = stats.t.interval(0.95, len(fold_scores)-1, loc=mean, scale=stats.sem(fold_scores))\n",
        "            scores[algorithm.getPredColName()] = [fold_scores, mean, ci_low, ci_high]\n",
        "            \n",
        "        results = scores    \n",
        "    \n",
        "        return results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eX0cQNy0zvlc",
        "outputId": "dcb03ac5-498f-4034-8229-5f2ca912be89"
      },
      "source": [
        "cv_patk = CrossValidationq6below('RMSE')\n",
        "cv_patk.run(algorithm_instances_Q6, num_users, num_items,k=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm user-cosine\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:86: RuntimeWarning: invalid value encountered in true_divide\n",
            "14310it [00:04, 2950.22it/s]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:86: RuntimeWarning: invalid value encountered in true_divide\n",
            "14030it [00:04, 2978.51it/s]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:86: RuntimeWarning: invalid value encountered in true_divide\n",
            "14933it [00:04, 3012.70it/s]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:86: RuntimeWarning: invalid value encountered in true_divide\n",
            "15120it [00:05, 2938.17it/s]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:86: RuntimeWarning: invalid value encountered in true_divide\n",
            "15010it [00:05, 2931.27it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm item-cosine\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:100: RuntimeWarning: invalid value encountered in true_divide\n",
            "14310it [00:04, 3031.98it/s]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:100: RuntimeWarning: invalid value encountered in true_divide\n",
            "14030it [00:04, 2899.93it/s]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:100: RuntimeWarning: invalid value encountered in true_divide\n",
            "14933it [00:05, 2923.21it/s]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:100: RuntimeWarning: invalid value encountered in true_divide\n",
            "15120it [00:04, 3028.05it/s]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:100: RuntimeWarning: invalid value encountered in true_divide\n",
            "15010it [00:05, 2900.67it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'item-cosine': [[1.0372175391503462,\n",
              "   1.0133347175697316,\n",
              "   1.0042827850513003,\n",
              "   1.0094138887125197,\n",
              "   1.005713578907237],\n",
              "  1.013992501878227,\n",
              "  0.997292029923097,\n",
              "  1.030692973833357],\n",
              " 'user-cosine': [[1.0292964812509109,\n",
              "   1.0134988342423394,\n",
              "   1.0162441815962555,\n",
              "   1.0083129744573012,\n",
              "   1.0168529851897112],\n",
              "  1.0168410913473036,\n",
              "  1.0072353809052537,\n",
              "  1.0264468017893535]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JcFLQMgVaUAj"
      },
      "source": [
        "Q6) Analysis\r\n",
        "\r\n",
        "* For each metric the ave, low cI and high cI are considered.\r\n",
        "\r\n",
        "```\r\n",
        "{'item-cosine': [ 1.022, 1.006, 1.039,\r\n",
        "'user-cosine': [ 1.016, 1.007, 1.026}\r\n",
        "Above\r\n",
        "{'item-cosine': [ 1.051, 1.029, 1.073,\r\n",
        "'user-cosine': [ 1.056, 1.042, 1.071]}\r\n",
        "Full members \r\n",
        "{'item-cosine': [ 1.020, 1.006, 1.033,\r\n",
        "'user-cosine': [ 1.017, 1.009, 1.025}\r\n",
        "```\r\n",
        "\r\n",
        "* The RMSE values of below are less than Above. so the below perfomed better becuase in case for below we have more points (can see the number of iterations) and more vectors so better predictions. In the same way for full members as it has more information than either of the cases it performed slightly better.\r\n",
        "* But the above analysis cannot be generalized unless I see the other k values. Even I am changing the K values by 10 there is more diffence. There is tradeoof between number of vectors and number of ratings inside a vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGpAMJ8Ccrq4"
      },
      "source": [
        "# Validation\n",
        "# Constants for validation only\n",
        "ROW_NUM = 943\n",
        "COL_NUM = 1682\n",
        "RATING_COL = 'rating'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7R8INqWu0Iv5"
      },
      "source": [
        "def validateDataPreprocessor(path=MOVIELENS_DIR, getData=getData, getMatrix=CrossValidation.getMatrix):\n",
        "    validation_df = getData(path, 'u1.test')\n",
        "    try:\n",
        "        matrix = getMatrix(validation_df, ROW_NUM, COL_NUM, RATING_COL)\n",
        "    except:\n",
        "        print('dataPreprocessor function has error')\n",
        "        return\n",
        "    try:\n",
        "        assert(matrix.shape == (ROW_NUM,COL_NUM)),\\\n",
        "        \"Shape of matrix{0} doesn't match predefined shape (943,1682)\".format(matrix.shape)\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "    return validation_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8NiemQD0I1E"
      },
      "source": [
        "validation_df = validateDataPreprocessor()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbYOo4bh0b5M"
      },
      "source": [
        "\n",
        "### Baseline Recommendation Systems\n",
        "\n",
        "#### Popularity Based Recommendation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHpVXu_d0I3n"
      },
      "source": [
        "def validatePopularityRecSys(validation_df=validation_df, BaseLineRecSys = BaseLineRecSys):\n",
        "    popularity_recsys = BaseLineRecSys('popularity')\n",
        "    try:\n",
        "        popularity_recsys.predict_all(validation_df, ROW_NUM, COL_NUM)\n",
        "    except Exception as e:        \n",
        "        print('popularity function has error')\n",
        "        print(e)\n",
        "        return\n",
        "    try:\n",
        "        predictionMatrix = popularity_recsys.getModel()\n",
        "        assert(predictionMatrix.shape == (ROW_NUM, COL_NUM)),\\\n",
        "        \"Shape of matrix{0} doesn't match predefined shape ({1},{2})\"\\\n",
        "        .format(predictionMatrix.shape,ROW_NUM, COL_NUM)\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "\n",
        "validatePopularityRecSys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFA5rvbd0jN5"
      },
      "source": [
        "#### User Average Based Recommendation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOUQserL0I8w"
      },
      "source": [
        "def validateUserAverRecSys(validation_df=validation_df, BaseLineRecSys = BaseLineRecSys):\n",
        "    useraverage_recsys = BaseLineRecSys('useraverage')\n",
        "    try:\n",
        "        useraverage_recsys.predict_all(validation_df, ROW_NUM, COL_NUM)\n",
        "    except:\n",
        "        print('useraverage function has error')\n",
        "        return\n",
        "    try:\n",
        "        predictionMatrix = useraverage_recsys.getModel()\n",
        "        assert(predictionMatrix.shape == (ROW_NUM, COL_NUM)),\\\n",
        "        \"Shape of matrix{0} doesn't match predefined shape ({1},{2})\"\\\n",
        "        .format(predictionMatrix.shape,ROW_NUM, COL_NUM)\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "\n",
        "validateUserAverRecSys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQE3qw-L0sWr"
      },
      "source": [
        "\n",
        "\n",
        "### Similary Based Recommendation Systems\n",
        "\n",
        "#### Euclidean Similarity Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9Pmcdn50JAH"
      },
      "source": [
        "def validateEuclidean(validation_df=validation_df, getMatrix=CrossValidation.getMatrix):\n",
        "    matrix = getMatrix(validation_df, ROW_NUM, COL_NUM, RATING_COL)\n",
        "    try:\n",
        "        sim_matrix = SimBasedRecSys.euclidean(matrix)\n",
        "        assert(sim_matrix.shape == (ROW_NUM, ROW_NUM)),\\\n",
        "        \"Shape of matrix{0} doesn't match predefined shape ({1},{2})\"\\\n",
        "        .format(sim_matrix.shape,ROW_NUM,ROW_NUM)\n",
        "        assert(np.any(sim_matrix <= 1)),\\\n",
        "               \"Exist similarity value that is not less or equal to 1.\"\n",
        "    except Exception as e:\n",
        "        print(e)        \n",
        "\n",
        "validateEuclidean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQifVk1X1B32"
      },
      "source": [
        "#### Customized Similarity Function (test somethingelse function)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jQnlA2e0I6l"
      },
      "source": [
        "def validateCustomizedSim(validation_df=validation_df, getMatrix=CrossValidation.getMatrix):\n",
        "    matrix = getMatrix(validation_df, ROW_NUM, COL_NUM, RATING_COL)\n",
        "    try:\n",
        "        sim_matrix = SimBasedRecSys.somethingelse(matrix)\n",
        "        assert(sim_matrix.shape == (ROW_NUM, ROW_NUM)),\\\n",
        "        \"Shape of matrix{0} doesn't match predefined shape ({1},{2})\"\\\n",
        "        .format(sim_matrix.shape,ROW_NUM,ROW_NUM)\n",
        "        assert(np.any(sim_matrix <= 1)),\\\n",
        "               \"Exist similarity value that is not less or equal to 1.\"\n",
        "    except Exception as e:\n",
        "        print(e) \n",
        "\n",
        "validateCustomizedSim()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKMw_-tq0_Bq"
      },
      "source": [
        "#### User-User Similarity Based Recommendation System"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ou1QKZou0Iy_"
      },
      "source": [
        "def validateUUSimBasedRecSys(validation_df=validation_df, dataPreprocessor=dataPreprocessor):\n",
        "    try:\n",
        "        user_cosine_recsys = SimBasedRecSys('user','cosine', dataPreprocessor)\n",
        "    except:\n",
        "        print(\"Framework error, please make sure you are using given yml file.\")\n",
        "        return\n",
        "    \n",
        "    try:\n",
        "        user_cosine_recsys.predict_all(validation_df, ROW_NUM, COL_NUM)\n",
        "        predictionMatrix = user_cosine_recsys.getModel()\n",
        "        assert(predictionMatrix.shape == (ROW_NUM, COL_NUM)),\\\n",
        "        \"Shape of matrix{0} doesn't match predefined shape ({1},{2})\"\\\n",
        "        .format(predictionMatrix.shape,ROW_NUM, COL_NUM)\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "\n",
        "validateUUSimBasedRecSys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LetKshXY07Y2"
      },
      "source": [
        "#### Item-Item Similarity Based Recommendation System"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SL_vF9tBzvc9"
      },
      "source": [
        "def validateIISimBasedRecSys(validation_df=validation_df, dataPreprocessor=dataPreprocessor):\n",
        "    try:\n",
        "        user_cosine_recsys = SimBasedRecSys('item','cosine', dataPreprocessor)\n",
        "    except:\n",
        "        print(\"Framework error, please make sure you are using given yml file.\")\n",
        "        return\n",
        "    \n",
        "    try:\n",
        "        user_cosine_recsys.predict_all(validation_df, ROW_NUM, COL_NUM)\n",
        "        predictionMatrix = user_cosine_recsys.getModel()\n",
        "        assert(predictionMatrix.shape == (ROW_NUM, COL_NUM)),\\\n",
        "        \"Shape of matrix{0} doesn't match predefined shape ({1},{2})\"\\\n",
        "        .format(predictionMatrix.shape,ROW_NUM, COL_NUM)\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "\n",
        "validateIISimBasedRecSys()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}